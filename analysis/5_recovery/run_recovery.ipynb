{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad24b3a8",
   "metadata": {},
   "source": [
    "# Recuperación de GW usando series sintéticas de precipitación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ac88c077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping well 2942002: missing baseline monthly mean\n",
      "Skipping well 2942003: missing baseline monthly mean\n",
      "Skipping well 2942006: missing baseline monthly mean\n",
      "Skipping well 5120012: missing baseline monthly mean\n",
      "Skipping well 5520023: missing baseline monthly mean\n",
      "Skipping well 5520024: missing baseline monthly mean\n",
      "Skipping well 5713014: missing baseline monthly mean\n",
      "Skipping well 5730036: missing baseline monthly mean\n",
      "Skipping well 5731005: missing baseline monthly mean\n",
      "Skipping well 5731006: missing baseline monthly mean\n",
      "Skipping well 5732008: missing baseline monthly mean\n",
      "Skipping well 5732011: missing baseline monthly mean\n",
      "Skipping well 5733013: missing baseline monthly mean\n",
      "Skipping well 5734010: missing baseline monthly mean\n",
      "Skipping well 5735011: missing baseline monthly mean\n",
      "Skipping well 5737014: missing baseline monthly mean\n",
      "Skipping well 5744008: missing baseline monthly mean\n",
      "Skipping well 6130004: missing baseline monthly mean\n",
      "Skipping well 6131001: missing baseline monthly mean\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "\n",
    "sys.path.append(str(Path('..').resolve()))\n",
    "from fun_LR_hydro_memory import make_lag_ranges, rolling_predictors\n",
    "\n",
    "out_figs = 'figs_gw_recovery'\n",
    "os.makedirs(out_figs, exist_ok=True)\n",
    "csv_dir = Path('csv')\n",
    "csv_dir.mkdir(exist_ok=True)\n",
    "\n",
    "gw_sim_store = {\n",
    "    'hist': {},\n",
    "    'sce1': {},\n",
    "    'sce2': {},\n",
    "    'sce3': {}\n",
    "}\n",
    "\n",
    "p_sim_store = {\n",
    "    'hist': {},\n",
    "    'sce1': {},\n",
    "    'sce2': {},\n",
    "    'sce3': {}\n",
    "}\n",
    "\n",
    "# === Configuration ===\n",
    "selected_lag_type_gw = 'type2_incr4'\n",
    "lag_ranges, _, _ = make_lag_ranges(lag_increase=4, n_windows=6, incr_type=2)\n",
    "\n",
    "# === Load observed series ===\n",
    "df_obs = pd.read_csv('../../data/ms_data/wells_gw.csv', parse_dates=['date'])\n",
    "df_pr = pd.read_csv('../../data/ms_data/wells_pr.csv', parse_dates=['date'])\n",
    "\n",
    "start = '1960-01-01'\n",
    "end = '2024-12-01'\n",
    "# Reindex to the requested window so missing months appear as NaN\n",
    "full_months = pd.date_range(start=start, end=end, freq='MS')\n",
    "def _reindex_monthly(df):\n",
    "    df = df.set_index('date').reindex(full_months)\n",
    "    df.index.name = 'date'\n",
    "    return df.reset_index()\n",
    "df_obs = _reindex_monthly(df_obs)\n",
    "df_pr = _reindex_monthly(df_pr)\n",
    "\n",
    "\n",
    "\n",
    "# === Load previous results (to filter data)===\n",
    "df_r2 = pd.read_csv('../4_GW_Q_memory/csv/gw_memory.csv', dtype={'well_id': str})\n",
    "eligible_wells = df_r2['well_id'].unique()\n",
    "cutoff_date = '2009-12-31'\n",
    "\n",
    "for well_id in eligible_wells:\n",
    "    \n",
    "    obs_abs = df_obs.set_index('date')[well_id].sort_index().asfreq('MS')\n",
    "    pr_abs = df_pr.set_index('date')[well_id].sort_index().asfreq('MS')\n",
    "\n",
    "    # obs_an = obs_abs - obs_abs.groupby(obs_abs.index.month).transform('mean')\n",
    "    # pr_an = pr_abs - pr_abs.groupby(pr_abs.index.month).transform('mean')\n",
    "\n",
    "    obs_baseline = obs_abs.where(obs_abs.index <= cutoff_date)\n",
    "    pr_baseline = pr_abs.where(pr_abs.index <= cutoff_date)\n",
    "\n",
    "    # === Relevant mean values ===\n",
    "    mon_mean_obs_abs = obs_baseline.groupby(obs_baseline.index.month).mean()\n",
    "    mon_mean_pr = pr_baseline.groupby(pr_baseline.index.month).mean()\n",
    "\n",
    "    if mon_mean_obs_abs.isna().any() or mon_mean_pr.isna().any():\n",
    "        print(f\"Skipping well {well_id}: missing baseline monthly mean\")\n",
    "        continue\n",
    "\n",
    "    obs_an = obs_abs - obs_baseline.groupby(obs_baseline.index.month).transform('mean')\n",
    "    pr_an = pr_abs - pr_baseline.groupby(pr_baseline.index.month).transform('mean')\n",
    "\n",
    "    winter_months = [6, 7, 8]\n",
    "\n",
    "    mean_obs_an_preMD = obs_an[obs_an.index < '01-01-2010'].mean()\n",
    "    mean_obs_abs_pre_MD = obs_abs[obs_abs.index < '01-01-2010'].mean()\n",
    "\n",
    "    # === Build historical predictors & model ===\n",
    "    X_hist_df = rolling_predictors(pr_an, lag_ranges, standardize=False).dropna()\n",
    "    y_hist_full = obs_an.reindex(X_hist_df.index)\n",
    "    valid_mask = y_hist_full.notna() & np.isfinite(y_hist_full.values)\n",
    "    valid_mask &= np.all(np.isfinite(X_hist_df.values), axis=1)\n",
    "\n",
    "    X_hist_clean = X_hist_df.loc[valid_mask]\n",
    "    y_hist_clean = y_hist_full.loc[valid_mask]\n",
    "\n",
    "    future_months = 120\n",
    "    last_hist_date = pr_an.index.max()\n",
    "    future_index = pd.date_range(last_hist_date + pd.offsets.MonthBegin(1), periods=future_months, freq='MS')\n",
    "    future_start = future_index[0]\n",
    "\n",
    "    pr_sce1 = pd.Series(0.0, index=future_index)\n",
    "    pr_full_sce1 = pd.concat([pr_an, pr_sce1])\n",
    "\n",
    "    pr_sce2 = pd.Series(0.0, index=future_index)\n",
    "    winter_mask = pr_sce2.index.month.isin(winter_months)\n",
    "    pr_sce2[winter_mask] = pr_sce2.index[winter_mask].map(lambda dt: 0.1 * mon_mean_pr.loc[winter_months].mean())\n",
    "    pr_full_sce2 = pd.concat([pr_an, pr_sce2])\n",
    "\n",
    "    pr_sce3 = pd.Series(0.0, index=future_index)\n",
    "    winter_mask = pr_sce3.index.month.isin(winter_months)\n",
    "    pr_sce3[winter_mask] = pr_sce3.index[winter_mask].map(lambda dt: 0.3 * mon_mean_pr.loc[winter_months].mean())\n",
    "    pr_full_sce3 = pd.concat([pr_an, pr_sce3])\n",
    "\n",
    "    p_sim_store['hist'][well_id] = pr_an.sort_index()\n",
    "    p_sim_store['sce1'][well_id] = pr_sce1.sort_index()\n",
    "    p_sim_store['sce2'][well_id] = pr_sce2.sort_index()\n",
    "    p_sim_store['sce3'][well_id] = pr_sce3.sort_index()\n",
    "\n",
    "\n",
    "    if X_hist_clean.empty or y_hist_clean.empty:\n",
    "        print(f\"Skipping well {well_id}: insufficient training data\")\n",
    "        continue\n",
    "\n",
    "    model = LinearRegression().fit(X_hist_clean.values, y_hist_clean.values)\n",
    "    r2_hist = r2_score(y_hist_clean.values, model.predict(X_hist_clean.values))\n",
    "\n",
    "    def predict_series(features_df):\n",
    "        features_df = features_df.dropna()\n",
    "        finite_mask = np.all(np.isfinite(features_df.values), axis=1)\n",
    "        features_clean = features_df.loc[finite_mask]\n",
    "        preds = model.predict(features_clean.values)\n",
    "        return pd.Series(preds, index=features_clean.index)\n",
    "\n",
    "    # === Predictions for historical period ===\n",
    "    obs_sim_hist = predict_series(X_hist_df)\n",
    "\n",
    "    # === Future Precipitation Scenarios (10 years) ===\n",
    "    label_sce1 = 'S1: avg precip'\n",
    "    X_df_sce1 = rolling_predictors(pr_full_sce1, lag_ranges, standardize=False).dropna()\n",
    "    obs_sim_full_sce1 = predict_series(X_df_sce1)\n",
    "    obs_sim_sce1 = obs_sim_full_sce1[obs_sim_full_sce1.index >= future_start]\n",
    "\n",
    "    label_sce2 = 'S2: +10% winter surplus'\n",
    "    X_df_sce2 = rolling_predictors(pr_full_sce2, lag_ranges, standardize=False).dropna()\n",
    "    obs_sim_full_sce2 = predict_series(X_df_sce2)\n",
    "    obs_sim_sce2 = obs_sim_full_sce2[obs_sim_full_sce2.index >= future_start]\n",
    "\n",
    "    label_sce3 = 'S3: +30% winter surplus'\n",
    "    X_df_sce3 = rolling_predictors(pr_full_sce3, lag_ranges, standardize=False).dropna()\n",
    "    obs_sim_full_sce3 = predict_series(X_df_sce3)\n",
    "    obs_sim_sce3 = obs_sim_full_sce3[obs_sim_full_sce3.index >= future_start]\n",
    "\n",
    "    def add_monthly_mean_offset(series, monthly_means):\n",
    "        offsets = pd.Series(series.index.month, index=series.index).map(monthly_means)\n",
    "        if offsets.isna().any():\n",
    "            raise ValueError('Monthly mean missing for at least one month in series index.')\n",
    "        return series + offsets\n",
    "\n",
    "    # === Compute absolute values ===\n",
    "    try:\n",
    "        obs_sim_abs_hist = add_monthly_mean_offset(obs_sim_hist, mon_mean_obs_abs)\n",
    "        obs_sim_abs_sce1 = add_monthly_mean_offset(obs_sim_sce1, mon_mean_obs_abs)\n",
    "        obs_sim_abs_sce2 = add_monthly_mean_offset(obs_sim_sce2, mon_mean_obs_abs)\n",
    "        obs_sim_abs_sce3 = add_monthly_mean_offset(obs_sim_sce3, mon_mean_obs_abs)\n",
    "        \n",
    "        gw_sim_store['hist'][well_id] = obs_sim_abs_hist.sort_index()\n",
    "        gw_sim_store['sce1'][well_id] = obs_sim_abs_sce1.sort_index()\n",
    "        gw_sim_store['sce2'][well_id] = obs_sim_abs_sce2.sort_index()\n",
    "        gw_sim_store['sce3'][well_id] = obs_sim_abs_sce3.sort_index()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    except ValueError as exc:\n",
    "        print(f\"Skipping well {well_id}: {exc}\")\n",
    "        continue\n",
    "    # === Smooth absolute values (6-month rolling mean) ===\n",
    "    window_months = 6\n",
    "    obs_sim_abs_hist_smooth = obs_sim_abs_hist.rolling(window=window_months, min_periods=1).mean()\n",
    "    obs_sim_abs_sce1_smooth = obs_sim_abs_sce1.rolling(window=window_months, min_periods=1).mean()\n",
    "    obs_sim_abs_sce2_smooth = obs_sim_abs_sce2.rolling(window=window_months, min_periods=1).mean()\n",
    "    obs_sim_abs_sce3_smooth = obs_sim_abs_sce3.rolling(window=window_months, min_periods=1).mean()\n",
    "\n",
    "    # === Plot ===\n",
    "    # plt.figure(figsize=(10, 4))\n",
    "    # plt.scatter(obs_an.index, obs_an.values, label='Obs GW ', color='black', alpha=0.8, s=6, zorder = 5)\n",
    "    # plt.plot(obs_sim_hist.index, obs_sim_hist.values, label=f'Sim GW (R²={r2_hist:.2f})', color='tab:blue', lw=.8)\n",
    "    # plt.plot(obs_sim_sce1.index, obs_sim_sce1.values, label=label_sce1, color='tab:orange', lw=.8)\n",
    "    # plt.plot(obs_sim_sce2.index, obs_sim_sce2.values, label=label_sce2, color='tab:green', lw=.8)\n",
    "    # plt.plot(obs_sim_sce3.index, obs_sim_sce3.values, label=label_sce3, color='tab:purple', lw=.8)\n",
    "    # plt.axvline(future_start, color='gray', linestyle='--', alpha=0.6)\n",
    "    # plt.axhline(mean_obs_an_preMD, color='k', linestyle='--', linewidth=0.8)\n",
    "    # plt.legend()\n",
    "    # plt.xlabel('Date')\n",
    "    # plt.ylabel('GW anomaly (m)')\n",
    "    # plt.title(f'Well {well_id} GW recovery')\n",
    "    # plt.tight_layout()\n",
    "    # plt.close()\n",
    "\n",
    "    # === Plot absolute values ===\n",
    "    plt.figure(figsize=(5.5, 3.5))\n",
    "    plt.scatter(obs_abs.index, obs_abs.values, label='Obs GW ', color='black', alpha=0.8, s=4, zorder = 5)\n",
    "    plt.plot(obs_sim_abs_hist_smooth.index, obs_sim_abs_hist_smooth.values, label=f'Sim GW (R²={r2_hist:.2f})', color='tab:blue', lw=.8)\n",
    "    plt.plot(obs_sim_abs_sce1_smooth.index, obs_sim_abs_sce1_smooth.values, label=label_sce1, color='tab:orange', lw=.8)\n",
    "    plt.plot(obs_sim_abs_sce2_smooth.index, obs_sim_abs_sce2_smooth.values, label=label_sce2, color='tab:green', lw=.8)\n",
    "    plt.plot(obs_sim_abs_sce3_smooth.index, obs_sim_abs_sce3_smooth.values, label=label_sce3, color='tab:purple', lw=.8)\n",
    "    plt.axvline(future_start, color='purple', linestyle='-', alpha=0.8, linewidth=1)\n",
    "    plt.axhline(mean_obs_abs_pre_MD, color='k', linestyle='--', linewidth=0.8)\n",
    "    plt.legend(loc='lower left', fontsize=8)\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('GW (m)')\n",
    "    plt.title(f'GW recovery: Well {well_id}')\n",
    "    plt.tight_layout()\n",
    "    plt.grid(True, color='grey', linestyle='-', linewidth=0.5, alpha=0.3)\n",
    "    plt.savefig(os.path.join(out_figs, f\"gw_recovery_{well_id}.png\"), bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "# === Save GW simulations to CSV ===\n",
    "for suffix, data_map in gw_sim_store.items():\n",
    "    if not data_map:\n",
    "        continue\n",
    "    df_out = pd.DataFrame(data_map).sort_index()\n",
    "    df_out.index.name = 'date'\n",
    "    df_out.to_csv(csv_dir / f'gw_sim_{suffix}.csv')\n",
    "\n",
    "# === Save precip simulations to CSV ===\n",
    "for suffix, data_map in p_sim_store.items():\n",
    "    if not data_map:\n",
    "        continue\n",
    "    df_out = pd.DataFrame(data_map).sort_index()\n",
    "    df_out.index.name = 'date'\n",
    "    df_out.to_csv(csv_dir / f'p_sim_{suffix}_well.csv')\n",
    "    \n",
    "# === Recovery time diagnostics ===\n",
    "# def first_recovery(series, threshold=0.05):\n",
    "#     mask = np.abs(series.values) < threshold\n",
    "#     if not mask.any():\n",
    "#         return None\n",
    "#     return series.index[mask.argmax()]\n",
    "\n",
    "# print('Recovery (|GW| < 0.05 m)')\n",
    "# rec_hist = first_recovery(obs_sim_hist)\n",
    "# print(f\"  Historical model: {rec_hist.date() if rec_hist else 'No recovery in historical period'}\")\n",
    "# rec_zero = first_recovery(scenario_splits['zero_future'])\n",
    "# print(f\"  Future scenario (zero anomaly): {rec_zero.date() if rec_zero else 'No recovery in next 10 years'}\")\n",
    "# rec_surplus = first_recovery(scenario_splits['surplus_future'])\n",
    "# print(f\"  Future scenario (+30% winter surplus): {rec_surplus.date() if rec_surplus else 'No recovery in next 10 years'}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3a5183e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping well 8220008: missing baseline monthly mean\n",
      "Skipping well 8220010: missing baseline monthly mean\n",
      "Skipping well 7200002: missing baseline monthly mean\n",
      "Skipping well 10133000: missing baseline monthly mean\n",
      "Skipping well 12876004: missing baseline monthly mean\n",
      "Skipping well 8316002: missing baseline monthly mean\n",
      "Skipping well 9400000: missing baseline monthly mean\n",
      "Skipping well 11500002: missing baseline monthly mean\n",
      "Skipping well 5720001: missing baseline monthly mean\n",
      "Skipping well 10313001: missing baseline monthly mean\n",
      "Skipping well 12286002: missing baseline monthly mean\n",
      "Skipping well 8700003: missing baseline monthly mean\n",
      "Skipping well 8821006: missing baseline monthly mean\n"
     ]
    }
   ],
   "source": [
    "# === Streamflow recovery analysis ===\n",
    "out_figs_q = 'figs_q_recovery'\n",
    "os.makedirs(out_figs_q, exist_ok=True)\n",
    "csv_dir = Path('csv')\n",
    "csv_dir.mkdir(exist_ok=True)\n",
    "\n",
    "q_sim_store = {\n",
    "    'hist': {},\n",
    "    'sce1': {},\n",
    "    'sce2': {},\n",
    "    'sce3': {}\n",
    "}\n",
    "\n",
    "p_sim_store = {\n",
    "    'hist': {},\n",
    "    'sce1': {},\n",
    "    'sce2': {},\n",
    "    'sce3': {}\n",
    "}\n",
    "\n",
    "selected_lag_type_q = 'type1_incr1'\n",
    "lag_ranges_q, _, _ = make_lag_ranges(lag_increase=1, n_windows=6, incr_type=1)\n",
    "\n",
    "df_q = pd.read_csv('../../data/camels/camels_q_mm.csv', parse_dates=['date'])\n",
    "df_pr_q = pd.read_csv('../../data/camels/camels_pr_mm.csv', parse_dates=['date'])\n",
    "\n",
    "# Reindex to the requested window so missing months appear as NaN\n",
    "full_months = pd.date_range(start=start, end=end, freq='MS')\n",
    "def _reindex_monthly(df):\n",
    "    df = df.set_index('date').reindex(full_months)\n",
    "    df.index.name = 'date'\n",
    "    return df.reset_index()\n",
    "df_q = _reindex_monthly(df_q)\n",
    "df_pr_q = _reindex_monthly(df_pr_q)\n",
    "\n",
    "\n",
    "df_r2_q = pd.read_csv('../3_run_LR_Q/csv/r2_LR_rest_pos_False_trained_all.csv', dtype={'gauge_id': str})\n",
    "eligible_gauges = set(df_r2_q[df_r2_q['r2_all'] > 0.4]['gauge_id'].unique())\n",
    "# cutoff_date = '2009-12-31'\n",
    "\n",
    "for gauge_id in eligible_gauges:\n",
    "    q_abs = df_q.set_index('date')[gauge_id].sort_index().asfreq('MS')\n",
    "    pr_abs = df_pr_q.set_index('date')[gauge_id].sort_index().asfreq('MS')\n",
    "\n",
    "    q_baseline = q_abs.where(q_abs.index <= cutoff_date)\n",
    "    pr_baseline = pr_abs.where(pr_abs.index <= cutoff_date)\n",
    "\n",
    "    # === Relevant mean values ===\n",
    "    mon_mean_q_abs = q_baseline.groupby(q_baseline.index.month).mean()\n",
    "    mon_mean_pr = pr_baseline.groupby(pr_baseline.index.month).mean()\n",
    "\n",
    "    if mon_mean_q_abs.isna().any() or mon_mean_pr.isna().any():\n",
    "        print(f\"Skipping well {gauge_id}: missing baseline monthly mean\")\n",
    "        continue\n",
    "\n",
    "    q_an = q_abs - q_baseline.groupby(q_baseline.index.month).transform('mean')\n",
    "    pr_an = pr_abs - pr_baseline.groupby(pr_baseline.index.month).transform('mean')\n",
    "\n",
    "    winter_months = [6, 7, 8]\n",
    "\n",
    "    mean_q_an_preMD = q_an[q_an.index < '01-01-2010'].mean()\n",
    "    mean_q_abs_pre_MD = q_abs[q_abs.index < '01-01-2010'].mean()\n",
    "\n",
    "    X_hist_df = rolling_predictors(pr_an, lag_ranges_q, standardize=False).dropna()\n",
    "    y_hist_full = q_an.reindex(X_hist_df.index)\n",
    "    valid_mask = y_hist_full.notna() & np.isfinite(y_hist_full.values)\n",
    "    valid_mask &= np.all(np.isfinite(X_hist_df.values), axis=1)\n",
    "\n",
    "    X_hist_clean = X_hist_df.loc[valid_mask]\n",
    "    y_hist_clean = y_hist_full.loc[valid_mask]\n",
    "\n",
    "    future_months = 120\n",
    "    last_hist_date = pr_an.index.max()\n",
    "    future_index = pd.date_range(last_hist_date + pd.offsets.MonthBegin(1), periods=future_months, freq='MS')\n",
    "    future_start = future_index[0]\n",
    "\n",
    "    pr_sce1 = pd.Series(0.0, index=future_index)\n",
    "    pr_full_sce1 = pd.concat([pr_an, pr_sce1])\n",
    "\n",
    "    pr_sce2 = pd.Series(0.0, index=future_index)\n",
    "    winter_mask = pr_sce2.index.month.isin(winter_months)\n",
    "    pr_sce2[winter_mask] = pr_sce2.index[winter_mask].map(lambda dt: 0.1 * mon_mean_pr.loc[winter_months].mean())\n",
    "    pr_full_sce2 = pd.concat([pr_an, pr_sce2])\n",
    "\n",
    "    pr_sce3 = pd.Series(0.0, index=future_index)\n",
    "    winter_mask = pr_sce3.index.month.isin(winter_months)\n",
    "    pr_sce3[winter_mask] = pr_sce3.index[winter_mask].map(lambda dt: 0.3 * mon_mean_pr.loc[winter_months].mean())\n",
    "    pr_full_sce3 = pd.concat([pr_an, pr_sce3])\n",
    "\n",
    "    p_sim_store['hist'][gauge_id] = pr_an.sort_index()\n",
    "    p_sim_store['sce1'][gauge_id] = pr_sce1.sort_index()\n",
    "    p_sim_store['sce2'][gauge_id] = pr_sce2.sort_index()\n",
    "    p_sim_store['sce3'][gauge_id] = pr_sce3.sort_index()\n",
    "\n",
    "    if X_hist_clean.empty or y_hist_clean.empty:\n",
    "        print(f'Skipping gauge {gauge_id}: insufficient training data')\n",
    "        continue\n",
    "\n",
    "    model = LinearRegression().fit(X_hist_clean.values, y_hist_clean.values)\n",
    "    r2_hist = r2_score(y_hist_clean.values, model.predict(X_hist_clean.values))\n",
    "\n",
    "    def predict_series(features_df):\n",
    "        features_df = features_df.dropna()\n",
    "        finite_mask = np.all(np.isfinite(features_df.values), axis=1)\n",
    "        features_clean = features_df.loc[finite_mask]\n",
    "        if features_clean.empty:\n",
    "            return pd.Series(dtype=float)\n",
    "        preds = model.predict(features_clean.values)\n",
    "        return pd.Series(preds, index=features_clean.index)\n",
    "\n",
    "    obs_sim_hist = predict_series(X_hist_df)\n",
    "\n",
    "    label_sce1 = 'S1: avg precip'\n",
    "    X_df_sce1 = rolling_predictors(pr_full_sce1, lag_ranges_q, standardize=False).dropna()\n",
    "    obs_sim_full_sce1 = predict_series(X_df_sce1)\n",
    "    obs_sim_sce1 = obs_sim_full_sce1[obs_sim_full_sce1.index >= future_start]\n",
    "\n",
    "    label_sce2 = 'S2: +10% winter surplus'\n",
    "    X_df_sce2 = rolling_predictors(pr_full_sce2, lag_ranges_q, standardize=False).dropna()\n",
    "    obs_sim_full_sce2 = predict_series(X_df_sce2)\n",
    "    obs_sim_sce2 = obs_sim_full_sce2[obs_sim_full_sce2.index >= future_start]\n",
    "\n",
    "    label_sce3 = 'S3: +30% winter surplus'\n",
    "    X_df_sce3 = rolling_predictors(pr_full_sce3, lag_ranges_q, standardize=False).dropna()\n",
    "    obs_sim_full_sce3 = predict_series(X_df_sce3)\n",
    "    obs_sim_sce3 = obs_sim_full_sce3[obs_sim_full_sce3.index >= future_start]\n",
    "\n",
    "    def add_monthly_mean_offset(series, monthly_means):\n",
    "        offsets = pd.Series(series.index.month, index=series.index).map(monthly_means)\n",
    "        if offsets.isna().any():\n",
    "            raise ValueError('Monthly mean missing for at least one month in series index.')\n",
    "        return series + offsets\n",
    "\n",
    "    try:\n",
    "        obs_sim_abs_hist = add_monthly_mean_offset(obs_sim_hist, mon_mean_q_abs).clip(lower=0)\n",
    "        obs_sim_abs_sce1 = add_monthly_mean_offset(obs_sim_sce1, mon_mean_q_abs).clip(lower=0)\n",
    "        obs_sim_abs_sce2 = add_monthly_mean_offset(obs_sim_sce2, mon_mean_q_abs).clip(lower=0)\n",
    "        obs_sim_abs_sce3 = add_monthly_mean_offset(obs_sim_sce3, mon_mean_q_abs).clip(lower=0)\n",
    "        \n",
    "        q_sim_store['hist'][gauge_id] = obs_sim_abs_hist.sort_index()\n",
    "        q_sim_store['sce1'][gauge_id] = obs_sim_abs_sce1.sort_index()\n",
    "        q_sim_store['sce2'][gauge_id] = obs_sim_abs_sce2.sort_index()\n",
    "        q_sim_store['sce3'][gauge_id] = obs_sim_abs_sce3.sort_index()\n",
    "\n",
    "\n",
    "        \n",
    "    except ValueError as exc:\n",
    "        print(f'Skipping gauge {gauge_id}: {exc}')\n",
    "        continue\n",
    "\n",
    "    window_months = 1\n",
    "    obs_sim_abs_hist_smooth = obs_sim_abs_hist.rolling(window=window_months, min_periods=1).mean()\n",
    "    obs_sim_abs_sce1_smooth = obs_sim_abs_sce1.rolling(window=window_months, min_periods=1).mean()\n",
    "    obs_sim_abs_sce2_smooth = obs_sim_abs_sce2.rolling(window=window_months, min_periods=1).mean()\n",
    "    obs_sim_abs_sce3_smooth = obs_sim_abs_sce3.rolling(window=window_months, min_periods=1).mean()\n",
    "\n",
    "    plt.figure(figsize=(5.5, 3.5))\n",
    "    plt.scatter(q_abs.index, q_abs.values, label='Obs Q', color='black', alpha=0.8, s=4, zorder=5)\n",
    "    plt.plot(obs_sim_abs_hist_smooth.index, obs_sim_abs_hist_smooth.values, label=f'Sim Q (R²={r2_hist:.2f})', color='tab:blue', lw=.8)\n",
    "    plt.plot(obs_sim_abs_sce1_smooth.index, obs_sim_abs_sce1_smooth.values, label=label_sce1, color='tab:orange', lw=.8)\n",
    "    plt.plot(obs_sim_abs_sce2_smooth.index, obs_sim_abs_sce2_smooth.values, label=label_sce2, color='tab:green', lw=.8)\n",
    "    plt.plot(obs_sim_abs_sce3_smooth.index, obs_sim_abs_sce3_smooth.values, label=label_sce3, color='tab:purple', lw=.8)\n",
    "    plt.axvline(future_start, color='purple', linestyle='-', alpha=0.6, linewidth=1)\n",
    "    plt.axhline(mean_q_abs_pre_MD, color='k', linestyle='--', linewidth=0.8)\n",
    "    plt.legend(loc='upper left', fontsize=8)\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Streamflow (mm)')\n",
    "    plt.title(f'Streamflow Recovery: Basin {gauge_id}')\n",
    "    plt.grid(True, color='grey', linestyle='-', linewidth=0.5, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(out_figs_q, f\"q_recovery_{gauge_id}.png\"), bbox_inches='tight',dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "# === Save streamflow simulations to CSV ===\n",
    "for suffix, data_map in q_sim_store.items():\n",
    "    if not data_map:\n",
    "        continue\n",
    "    df_out = pd.DataFrame(data_map).sort_index()\n",
    "    df_out.index.name = 'date'\n",
    "    df_out.to_csv(csv_dir / f'q_sim_{suffix}.csv')\n",
    "\n",
    "\n",
    "\n",
    "# === Save precip simulations to CSV ===\n",
    "for suffix, data_map in p_sim_store.items():\n",
    "    if not data_map:\n",
    "        continue\n",
    "    df_out = pd.DataFrame(data_map).sort_index()\n",
    "    df_out.index.name = 'date'\n",
    "    df_out.to_csv(csv_dir / f'p_sim_{suffix}_basin.csv')\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
