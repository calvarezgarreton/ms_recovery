{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3b7be64-06aa-4872-a05f-17411779964f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import os\n",
    "import re\n",
    "from scipy.interpolate import UnivariateSpline, PchipInterpolator\n",
    "from sklearn.isotonic import isotonic_regression\n",
    "\n",
    "def compute_memory_from_spline_variants(df_config, perc_max_r2=0.9, spline_smoothing=0.5):\n",
    "    \"\"\"\n",
    "    Compute memory estimates from a DataFrame built for a single well (well_data).\n",
    "\n",
    "    This minimal, robust implementation collects available (pred_memory1..6, r2_pred1..6)\n",
    "    pairs across the rows in `df_config`, filters out NaNs, and fits three curve variants\n",
    "    (UnivariateSpline, PCHIP, and isotonic) to estimate the predictor memory at which\n",
    "    R² first reaches `perc_max_r2` of the observed maximum R².\n",
    "\n",
    "    Returns a dict with keys: 'lag_type' (None here), 'memory_spline','memory_pchip','memory_iso',\n",
    "    'x_vals','y_spline','y_pchip','y_iso'.\n",
    "    \"\"\"\n",
    "    # Collect x (memory) and y (r2) pairs from available columns\n",
    "    x_list = []\n",
    "    y_list = []\n",
    "    for _, row in df_config.iterrows():\n",
    "        for i in range(1, 7):\n",
    "            xm = row.get(f'pred_memory{i}', np.nan)\n",
    "            ym = row.get(f'r2_pred{i}', np.nan)\n",
    "            x_list.append(float(xm))\n",
    "            y_list.append(float(ym))\n",
    "\n",
    "    if len(x_list) == 0:\n",
    "        # nothing to fit\n",
    "        return {\n",
    "            'lag_type': None,\n",
    "            'memory_spline': np.nan,\n",
    "            'memory_pchip': np.nan,\n",
    "            'memory_iso': np.nan,\n",
    "            'x_vals': None,\n",
    "            'y_spline': None,\n",
    "            'y_pchip': None,\n",
    "            'y_iso': None\n",
    "        }\n",
    "\n",
    "    x = np.array(x_list)\n",
    "    y = np.array(y_list)\n",
    "\n",
    "    # Remove NaNs and sort by x\n",
    "    mask = ~np.isnan(x) & ~np.isnan(y)\n",
    "    x = x[mask]\n",
    "    y = y[mask]\n",
    "    if x.size == 0:\n",
    "        return {\n",
    "            'lag_type': None,\n",
    "            'memory_spline': np.nan,\n",
    "            'memory_pchip': np.nan,\n",
    "            'memory_iso': np.nan,\n",
    "            'x_vals': None,\n",
    "            'y_spline': None,\n",
    "            'y_pchip': None,\n",
    "            'y_iso': None\n",
    "        }\n",
    "\n",
    "    idx = np.argsort(x)\n",
    "    x_sorted = x[idx]\n",
    "    y_sorted = y[idx]\n",
    "    x_dense = np.linspace(x_sorted.min(), x_sorted.max(), 500)\n",
    "    r2_target = perc_max_r2 * np.nanmax(y_sorted)\n",
    "\n",
    "    def first_cross(xvals, yvals, thr):\n",
    "        above = yvals >= thr\n",
    "        return xvals[np.argmax(above)] if np.any(above) else np.nan\n",
    "\n",
    "    # Spline\n",
    "    try:\n",
    "        spline = UnivariateSpline(x_sorted, y_sorted, s=spline_smoothing)\n",
    "        y_spline = spline(x_dense)\n",
    "        mem_spline = first_cross(x_dense, y_spline, r2_target)\n",
    "    except Exception:\n",
    "        y_spline = None\n",
    "        mem_spline = np.nan\n",
    "\n",
    "    # PCHIP\n",
    "    try:\n",
    "        pchip = PchipInterpolator(x_sorted, y_sorted)\n",
    "        y_pchip = pchip(x_dense)\n",
    "        mem_pchip = first_cross(x_dense, y_pchip, r2_target)\n",
    "    except Exception:\n",
    "        y_pchip = None\n",
    "        mem_pchip = np.nan\n",
    "\n",
    "    # Isotonic\n",
    "    try:\n",
    "        # prefer the functional API if available\n",
    "        try:\n",
    "            y_iso = isotonic_regression(y_sorted)\n",
    "        except Exception:\n",
    "            # fallback to estimator API\n",
    "            from sklearn.isotonic import IsotonicRegression\n",
    "            ir = IsotonicRegression()\n",
    "            # fit_transform expects X shape; use x_sorted as X to preserve monotonicity domain\n",
    "            y_iso = ir.fit_transform(x_sorted, y_sorted)\n",
    "        y_iso_dense = np.interp(x_dense, x_sorted, y_iso)\n",
    "        mem_iso = first_cross(x_dense, y_iso_dense, r2_target)\n",
    "    except Exception:\n",
    "        y_iso_dense = None\n",
    "        mem_iso = np.nan\n",
    "\n",
    "    return {\n",
    "        'lag_type': None,\n",
    "        'memory_spline': mem_spline,\n",
    "        'memory_pchip': mem_pchip,\n",
    "        'memory_iso': mem_iso,\n",
    "        'x_vals': x_dense,\n",
    "        'y_spline': y_spline,\n",
    "        'y_pchip': y_pchip,\n",
    "        'y_iso': y_iso_dense,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "533cfe73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping well 1110003: max_r2_selected=0.1977415128227484\n",
      "Skipping well 1110004: max_r2_selected=0.1367038365820868\n",
      "Skipping well 1110005: max_r2_selected=0.1261662037406052\n",
      "Skipping well 1110006: max_r2_selected=0.1338734190854104\n",
      "Skipping well 1110007: max_r2_selected=0.1541115264980965\n",
      "Skipping well 1110008: max_r2_selected=0.3548671600837521\n",
      "Skipping well 1110009: max_r2_selected=0.2699924650502709\n",
      "Skipping well 1110010: max_r2_selected=0.2471880665369325\n",
      "Skipping well 1211010: max_r2_selected=0.2204852589895463\n",
      "Skipping well 1310024: max_r2_selected=0.2417625729825818\n",
      "Skipping well 1310025: max_r2_selected=0.1295310917162614\n",
      "Skipping well 1310026: max_r2_selected=0.3248846769850262\n",
      "Skipping well 1310027: max_r2_selected=0.3412576022372298\n",
      "Skipping well 1310033: max_r2_selected=0.2920835299681475\n",
      "Skipping well 1310036: max_r2_selected=0.2395065321218863\n",
      "Skipping well 1310064: max_r2_selected=0.2333642602146154\n",
      "Skipping well 1310069: max_r2_selected=0.3197217481996868\n",
      "Skipping well 1700013: max_r2_selected=0.173275241699887\n",
      "Skipping well 1700019: max_r2_selected=0.1810599850147333\n",
      "Skipping well 1700023: max_r2_selected=0.027491313111674\n",
      "Skipping well 1700024: max_r2_selected=0.1042313197986019\n",
      "Skipping well 1700026: max_r2_selected=0.050986928729823\n",
      "Skipping well 1700030: max_r2_selected=0.0434955280731794\n",
      "Skipping well 1700032: max_r2_selected=0.0497519038725115\n",
      "Skipping well 1700042: max_r2_selected=0.0125758004416593\n",
      "Skipping well 1700043: max_r2_selected=0.09547390891377\n",
      "Skipping well 1700044: max_r2_selected=0.0586153881046163\n",
      "Skipping well 1700051: max_r2_selected=0.0083268340673284\n",
      "Skipping well 1700054: max_r2_selected=0.040145387174328\n",
      "Skipping well 1700057: max_r2_selected=0.0275098330594416\n",
      "Skipping well 1700059: max_r2_selected=0.0637563863794701\n",
      "Skipping well 1700063: max_r2_selected=0.0588050849252833\n",
      "Skipping well 1700073: max_r2_selected=0.1277535961311329\n",
      "Skipping well 1700074: max_r2_selected=0.1546965419744098\n",
      "Skipping well 1700076: max_r2_selected=0.0703986369169952\n",
      "Skipping well 1700084: max_r2_selected=0.1676905538951454\n",
      "Skipping well 1700086: max_r2_selected=0.0311422320093356\n",
      "Skipping well 1700092: max_r2_selected=0.3694441552968903\n",
      "Skipping well 1700098: max_r2_selected=0.1281658305690983\n",
      "Skipping well 1700105: max_r2_selected=0.382758896856285\n",
      "Skipping well 2105024: max_r2_selected=0.1786688772324489\n",
      "Skipping well 2105025: max_r2_selected=0.2933470015047357\n",
      "Skipping well 2105028: max_r2_selected=0.0891876111612594\n",
      "Skipping well 2105030: max_r2_selected=0.0175092154582336\n",
      "Skipping well 2110019: max_r2_selected=0.2514735440096655\n",
      "Skipping well 2942007: max_r2_selected=0.3689774999576804\n",
      "Skipping well 2942008: max_r2_selected=0.347832864928015\n",
      "Skipping well 2942009: max_r2_selected=0.3602612706794854\n",
      "Skipping well 2942010: max_r2_selected=0.3501387589675233\n",
      "Skipping well 2942015: max_r2_selected=0.1369629525352824\n",
      "Skipping well 2942021: max_r2_selected=0.1726289210482076\n",
      "Skipping well 3404003: max_r2_selected=0.377063698186051\n",
      "Skipping well 3421005: max_r2_selected=0.2488197493163126\n",
      "Skipping well 3421006: max_r2_selected=0.3866645439694902\n",
      "Skipping well 3430008: max_r2_selected=0.3666569067452714\n",
      "Skipping well 3430009: max_r2_selected=0.3493661910943066\n",
      "Skipping well 3430010: max_r2_selected=0.2269726750597864\n",
      "Skipping well 3430011: max_r2_selected=0.1813205362741976\n",
      "Skipping well 3431009: max_r2_selected=0.3420804150033627\n",
      "Skipping well 3431010: max_r2_selected=0.2190599570910845\n",
      "Skipping well 3450005: max_r2_selected=0.3341383919844499\n",
      "Skipping well 3450015: max_r2_selected=0.2588957843806089\n",
      "Skipping well 3450016: max_r2_selected=0.3616139027914249\n",
      "Skipping well 3451004: max_r2_selected=0.0874777760958796\n",
      "Skipping well 3451006: max_r2_selected=0.0880956208864429\n",
      "Skipping well 3451008: max_r2_selected=0.2945343742642854\n",
      "Skipping well 3451012: max_r2_selected=0.1770801577068075\n",
      "Skipping well 3451016: max_r2_selected=0.3946436739248752\n",
      "Skipping well 3451017: max_r2_selected=0.2959409738518234\n",
      "Skipping well 3451018: max_r2_selected=0.1013738027157374\n",
      "Skipping well 3451019: max_r2_selected=0.2475414504970699\n",
      "Skipping well 3451020: max_r2_selected=0.0349935370728043\n",
      "Skipping well 3451021: max_r2_selected=0.278425644156097\n",
      "Skipping well 3453006: max_r2_selected=0.0679282196162218\n",
      "Skipping well 3453007: max_r2_selected=0.196571890472174\n",
      "Skipping well 3603001: max_r2_selected=0.1874579612555905\n",
      "Skipping well 3700001: max_r2_selected=0.0369688039080553\n",
      "Skipping well 3701002: max_r2_selected=0.0288403552994239\n",
      "Skipping well 3701004: max_r2_selected=0.0563690391794661\n",
      "Skipping well 3701005: max_r2_selected=0.0487494451180726\n",
      "Skipping well 3701007: max_r2_selected=0.1169837259806857\n",
      "Skipping well 3804008: max_r2_selected=0.1554169169609293\n",
      "Skipping well 3806003: max_r2_selected=0.1393996545175346\n",
      "Skipping well 3806004: max_r2_selected=0.0660762164810543\n",
      "Skipping well 3814004: max_r2_selected=0.2559074898187966\n",
      "Skipping well 3815005: max_r2_selected=0.1777868221154426\n",
      "Skipping well 3823005: max_r2_selected=0.0614729397610531\n",
      "Skipping well 3823006: max_r2_selected=0.0404793792593431\n",
      "Skipping well 3825005: max_r2_selected=0.1936072853525726\n",
      "Skipping well 3825006: max_r2_selected=0.1158652731079699\n",
      "Skipping well 3826004: max_r2_selected=0.0308731814596286\n",
      "Skipping well 3826005: max_r2_selected=0.0678683061226435\n",
      "Skipping well 3826006: max_r2_selected=0.2308819881319751\n",
      "Skipping well 3940006: max_r2_selected=0.389503904828572\n",
      "Skipping well 4100002: max_r2_selected=0.3142653926110141\n",
      "Skipping well 4120002: max_r2_selected=0.3825187311285796\n",
      "Skipping well 4120006: max_r2_selected=0.1066749399632556\n",
      "Skipping well 4120007: max_r2_selected=0.1076266956493063\n",
      "Skipping well 4120008: max_r2_selected=0.1581623926962304\n",
      "Skipping well 4120009: max_r2_selected=0.0811058596468745\n",
      "Skipping well 4120010: max_r2_selected=0.3131040619279424\n",
      "Skipping well 4120012: max_r2_selected=0.1475840120056158\n",
      "Skipping well 4120015: max_r2_selected=0.2486245673697937\n",
      "Skipping well 4120016: max_r2_selected=0.1859413623535529\n",
      "Skipping well 4200007: max_r2_selected=0.2071445424778585\n",
      "Skipping well 4200008: max_r2_selected=0.1068613938314782\n",
      "Skipping well 4200009: max_r2_selected=0.1552477480805166\n",
      "Skipping well 4308005: max_r2_selected=0.3540759932777437\n",
      "Skipping well 4314004: max_r2_selected=0.257950121505266\n",
      "Skipping well 4314005: max_r2_selected=0.1598104925816683\n",
      "Skipping well 4320011: max_r2_selected=0.3204399362816478\n",
      "Skipping well 4320014: max_r2_selected=0.324752273645632\n",
      "Skipping well 4320015: max_r2_selected=0.2287722689530112\n",
      "Skipping well 4321004: max_r2_selected=0.1887312904011654\n",
      "Skipping well 4323009: max_r2_selected=0.1263572024414209\n",
      "Skipping well 4323011: max_r2_selected=0.1885361843197703\n",
      "Skipping well 4323012: max_r2_selected=0.2915764595322127\n",
      "Skipping well 4323013: max_r2_selected=0.2070169389638345\n",
      "Skipping well 4330001: max_r2_selected=0.3750461276230292\n",
      "Skipping well 4331005: max_r2_selected=0.086102539058462\n",
      "Skipping well 4331006: max_r2_selected=0.2328060636446046\n",
      "Skipping well 4331008: max_r2_selected=0.1139505377860731\n",
      "Skipping well 4331010: max_r2_selected=0.1087450195218504\n",
      "Skipping well 4331017: max_r2_selected=0.1565530095878281\n",
      "Skipping well 4400003: max_r2_selected=0.0264283774001776\n",
      "Skipping well 4400006: max_r2_selected=0.2903804050367257\n",
      "Skipping well 4400007: max_r2_selected=0.1595373321438801\n",
      "Skipping well 4400008: max_r2_selected=0.1043629584760574\n",
      "Skipping well 4400011: max_r2_selected=0.0681496402365027\n",
      "Skipping well 4400013: max_r2_selected=0.1665278562883557\n",
      "Skipping well 4400014: max_r2_selected=0.2496453963014842\n",
      "Skipping well 4400017: max_r2_selected=0.375616471139768\n",
      "Skipping well 4400020: max_r2_selected=0.1599608120003449\n",
      "Skipping well 4400022: max_r2_selected=0.0577134608012365\n",
      "Skipping well 4400024: max_r2_selected=0.3553501991363715\n",
      "Skipping well 4400025: max_r2_selected=0.1645028378371018\n",
      "Skipping well 4400026: max_r2_selected=0.2580196349931314\n",
      "Skipping well 4400030: max_r2_selected=0.1279758751701382\n",
      "Skipping well 4400031: max_r2_selected=0.1266954077870479\n",
      "Skipping well 4400034: max_r2_selected=0.0915077599037304\n",
      "Skipping well 4400037: max_r2_selected=0.1756928732873809\n",
      "Skipping well 4400038: max_r2_selected=0.0535870871996365\n",
      "Skipping well 4503005: max_r2_selected=0.2778018028612087\n",
      "Skipping well 4506008: max_r2_selected=0.3352042108800498\n",
      "Skipping well 4506009: max_r2_selected=0.0933658129154438\n",
      "Skipping well 4516004: max_r2_selected=0.0835125718555815\n",
      "Skipping well 4524002: max_r2_selected=0.1555083514603426\n",
      "Skipping well 4531004: max_r2_selected=0.1254512573954717\n",
      "Skipping well 4531005: max_r2_selected=0.1192102321482193\n",
      "Skipping well 4537005: max_r2_selected=0.0386443289914367\n",
      "Skipping well 4540008: max_r2_selected=0.3293735663515296\n",
      "Skipping well 4540009: max_r2_selected=0.2056552867091609\n",
      "Skipping well 4550004: max_r2_selected=0.3662634706555014\n",
      "Skipping well 4550005: max_r2_selected=0.39219995743402\n",
      "Skipping well 4550008: max_r2_selected=0.0792344138554432\n",
      "Skipping well 4551007: max_r2_selected=0.0380146362773186\n",
      "Skipping well 4552003: max_r2_selected=0.1092778726954626\n",
      "Skipping well 4552004: max_r2_selected=0.0878755111179227\n",
      "Skipping well 4553005: max_r2_selected=0.2976510943306311\n",
      "Skipping well 4553008: max_r2_selected=0.3739843042431749\n",
      "Skipping well 4555002: max_r2_selected=0.2343675347878893\n",
      "Skipping well 4555003: max_r2_selected=0.2845597917092775\n",
      "Skipping well 4555005: max_r2_selected=0.1171149032049992\n",
      "Skipping well 4556002: max_r2_selected=0.0645990721862326\n",
      "Skipping well 4556003: max_r2_selected=0.1967494926038963\n",
      "Skipping well 4711005: max_r2_selected=0.3844038867582265\n",
      "Skipping well 4714002: max_r2_selected=0.2795650591255766\n",
      "Skipping well 4730005: max_r2_selected=0.217871899721818\n",
      "Skipping well 4735002: max_r2_selected=0.2008848665113356\n",
      "Skipping well 4735003: max_r2_selected=0.1586198991736471\n",
      "Skipping well 4810004: max_r2_selected=0.3536774534963189\n",
      "Skipping well 4902006: max_r2_selected=0.1633894644960738\n",
      "Skipping well 4902007: max_r2_selected=0.3672116773649779\n",
      "Skipping well 5200008: max_r2_selected=0.2738932876271392\n",
      "Skipping well 5210003: max_r2_selected=0.3948778324581389\n",
      "Skipping well 5210007: max_r2_selected=0.2990909614231452\n",
      "Skipping well 5210008: max_r2_selected=0.2370259658775222\n",
      "Skipping well 5220011: max_r2_selected=0.3774632491674924\n",
      "Skipping well 5221008: max_r2_selected=0.3189657396705854\n",
      "Skipping well 5420006: max_r2_selected=0.0650642405314852\n",
      "Skipping well 5420007: max_r2_selected=0.0413591779735818\n",
      "Skipping well 5420009: max_r2_selected=0.0257359993407731\n",
      "Skipping well 5422003: max_r2_selected=0.2486874846851184\n",
      "Skipping well 5423014: max_r2_selected=0.0806632626146053\n",
      "Skipping well 5423015: max_r2_selected=0.3487388266672321\n",
      "Skipping well 5423016: max_r2_selected=0.0503979911583184\n",
      "Skipping well 5423018: max_r2_selected=0.3480780364223295\n",
      "Skipping well 5423019: max_r2_selected=0.3915093160872855\n",
      "Skipping well 5423020: max_r2_selected=0.076384736354053\n",
      "Skipping well 5423024: max_r2_selected=0.1724010335202317\n",
      "Skipping well 5424006: max_r2_selected=0.1234156322641065\n",
      "Skipping well 5424010: max_r2_selected=0.2503606266695601\n",
      "Skipping well 5424012: max_r2_selected=0.2260839020327128\n",
      "Skipping well 5425004: max_r2_selected=0.1063935167097688\n",
      "Skipping well 5425005: max_r2_selected=0.0423067965948673\n",
      "Skipping well 5425006: max_r2_selected=0.1097182478949688\n",
      "Skipping well 5426005: max_r2_selected=0.1245728596882274\n",
      "Skipping well 5426006: max_r2_selected=0.1226551395121853\n",
      "Skipping well 5426007: max_r2_selected=0.1795288061841966\n",
      "Skipping well 5426008: max_r2_selected=0.0903725982830312\n",
      "Skipping well 5426009: max_r2_selected=0.2806134884837349\n",
      "Skipping well 5426011: max_r2_selected=0.0269016528528219\n",
      "Skipping well 5426012: max_r2_selected=0.3276761019900269\n",
      "Skipping well 5426014: max_r2_selected=0.3349507436837189\n",
      "Skipping well 5426015: max_r2_selected=0.1883413473346084\n",
      "Skipping well 5426016: max_r2_selected=0.2471159177997043\n",
      "Skipping well 5426017: max_r2_selected=0.2177709017465809\n",
      "Skipping well 5426019: max_r2_selected=0.2288232852028158\n",
      "Skipping well 5426020: max_r2_selected=0.3762041926170992\n",
      "Skipping well 5426022: max_r2_selected=0.1141265011432644\n",
      "Skipping well 5427010: max_r2_selected=0.148939063741626\n",
      "Skipping well 5427011: max_r2_selected=0.1672235936131964\n",
      "Skipping well 5427012: max_r2_selected=0.3730702940686086\n",
      "Skipping well 5428005: max_r2_selected=0.3386703443008347\n",
      "Skipping well 5428006: max_r2_selected=0.0546714094121264\n",
      "Skipping well 5428007: max_r2_selected=0.1782120723247893\n",
      "Skipping well 5520003: max_r2_selected=0.2398970460372038\n",
      "Skipping well 5520004: max_r2_selected=0.1974853061208973\n",
      "Skipping well 5520005: max_r2_selected=0.2946020802653253\n",
      "Skipping well 5520011: max_r2_selected=0.1920574289363714\n",
      "Skipping well 5520012: max_r2_selected=0.1971709047961018\n",
      "Skipping well 5520013: max_r2_selected=0.0991091898467735\n",
      "Skipping well 5520014: max_r2_selected=0.0921153655535854\n",
      "Skipping well 5710008: max_r2_selected=0.2115482586855682\n",
      "Skipping well 5711004: max_r2_selected=0.1589888081511993\n",
      "Skipping well 5713007: max_r2_selected=0.234712663485591\n",
      "Skipping well 5713009: max_r2_selected=0.2168666619227497\n",
      "Skipping well 5713010: max_r2_selected=0.3573248269015757\n",
      "Skipping well 5716006: max_r2_selected=0.1644228790957487\n",
      "Skipping well 5717009: max_r2_selected=0.0534377323538681\n",
      "Skipping well 5717010: max_r2_selected=0.1735773872175686\n",
      "Skipping well 5730017: max_r2_selected=0.3505395324142691\n",
      "Skipping well 5730019: max_r2_selected=0.3460634742727237\n",
      "Skipping well 5730020: max_r2_selected=0.3594397826110989\n",
      "Skipping well 5730023: max_r2_selected=0.3538678884328313\n",
      "Skipping well 5730026: max_r2_selected=0.0483137738829295\n",
      "Skipping well 5730033: max_r2_selected=nan\n",
      "Skipping well 5730034: max_r2_selected=0.3973707374101531\n",
      "Skipping well 5731001: max_r2_selected=0.2418058843916132\n",
      "Skipping well 5731002: max_r2_selected=0.2268214974510947\n",
      "Skipping well 5731003: max_r2_selected=0.3700689617480193\n",
      "Skipping well 5732003: max_r2_selected=0.06492979836084\n",
      "Skipping well 5732004: max_r2_selected=0.3888976187541567\n",
      "Skipping well 5732005: max_r2_selected=0.0913849904833008\n",
      "Skipping well 5732006: max_r2_selected=0.0919818600287678\n",
      "Skipping well 5732007: max_r2_selected=0.1001639217501574\n",
      "Skipping well 5734003: max_r2_selected=0.1329353499369832\n",
      "Skipping well 5734006: max_r2_selected=0.3349816864088232\n",
      "Skipping well 5734007: max_r2_selected=0.1527301643438686\n",
      "Skipping well 5734008: max_r2_selected=0.3656517560820205\n",
      "Skipping well 5735010: max_r2_selected=0.2431410715907527\n",
      "Skipping well 5735013: max_r2_selected=0.3060081470760505\n",
      "Skipping well 5735014: max_r2_selected=0.2903435043364507\n",
      "Skipping well 5736002: max_r2_selected=0.3915147384240713\n",
      "Skipping well 5737009: max_r2_selected=0.0941514031417274\n",
      "Skipping well 5737010: max_r2_selected=0.3460618382726236\n",
      "Skipping well 5737011: max_r2_selected=0.2487965983334673\n",
      "Skipping well 5737012: max_r2_selected=0.1060980884301744\n",
      "Skipping well 5737013: max_r2_selected=0.08603934756143\n",
      "Skipping well 5740006: max_r2_selected=0.0478357227759664\n",
      "Skipping well 5740007: max_r2_selected=0.3467947716845439\n",
      "Skipping well 5740008: max_r2_selected=0.081306513123311\n",
      "Skipping well 5740009: max_r2_selected=0.2069257221258287\n",
      "Skipping well 5744004: max_r2_selected=0.3060844822338072\n",
      "Skipping well 5744005: max_r2_selected=0.0625656424894347\n",
      "Skipping well 5744006: max_r2_selected=0.1019182071630516\n",
      "Skipping well 5744007: max_r2_selected=0.1076577337333373\n",
      "Skipping well 5745002: max_r2_selected=0.2301567960361392\n",
      "Skipping well 5745003: max_r2_selected=0.0601516761687733\n",
      "Skipping well 5747002: max_r2_selected=0.0994242127876882\n",
      "Skipping well 5747003: max_r2_selected=0.3082019884857476\n",
      "Skipping well 5747004: max_r2_selected=0.3910994260275773\n",
      "Skipping well 5747005: max_r2_selected=0.2924569761216058\n",
      "Skipping well 5747006: max_r2_selected=0.2573931852662093\n",
      "Skipping well 6011012: max_r2_selected=0.0286266597343855\n",
      "Skipping well 6011022: max_r2_selected=0.2604315133327932\n",
      "Skipping well 6011023: max_r2_selected=0.3533643364308204\n",
      "Skipping well 6012007: max_r2_selected=0.3740804318787454\n",
      "Skipping well 6012011: max_r2_selected=0.2070861807016785\n",
      "Skipping well 6012012: max_r2_selected=0.2494823902907015\n",
      "Skipping well 6012014: max_r2_selected=0.2300768935101167\n",
      "Skipping well 6012016: max_r2_selected=0.1509991698630046\n",
      "Skipping well 6012019: max_r2_selected=0.0635349512404145\n",
      "Skipping well 6013007: max_r2_selected=0.1109896468647637\n",
      "Skipping well 6014008: max_r2_selected=0.0209147385539592\n",
      "Skipping well 6015011: max_r2_selected=0.2789433213594018\n",
      "Skipping well 6015012: max_r2_selected=0.1695938329554329\n",
      "Skipping well 6015013: max_r2_selected=0.2551586770986557\n",
      "Skipping well 6015017: max_r2_selected=0.1019906183018792\n",
      "Skipping well 6015018: max_r2_selected=0.2852436916760948\n",
      "Skipping well 6015019: max_r2_selected=0.0735584181691334\n",
      "Skipping well 6016010: max_r2_selected=0.1303787006327302\n",
      "Skipping well 6016015: max_r2_selected=0.1093642278207785\n",
      "Skipping well 6017003: max_r2_selected=0.1477514898033593\n",
      "Skipping well 6018013: max_r2_selected=0.3363163126432186\n",
      "Skipping well 6018015: max_r2_selected=0.1158931671280077\n",
      "Skipping well 6018017: max_r2_selected=0.0430584775406803\n",
      "Skipping well 6019007: max_r2_selected=0.0926306036494101\n",
      "Skipping well 6019013: max_r2_selected=0.0909636686463504\n",
      "Skipping well 6019014: max_r2_selected=0.1116925390074438\n",
      "Skipping well 6030002: max_r2_selected=0.2034939401885743\n",
      "Skipping well 6030004: max_r2_selected=0.2987145022339851\n",
      "Skipping well 6030007: max_r2_selected=0.287118398508703\n",
      "Skipping well 6030009: max_r2_selected=0.2530648684742413\n",
      "Skipping well 6030010: max_r2_selected=0.3909862863873376\n",
      "Skipping well 6031001: max_r2_selected=0.1471266527097906\n",
      "Skipping well 6031003: max_r2_selected=0.0951864796025931\n",
      "Skipping well 6032002: max_r2_selected=0.1420757352065544\n",
      "Skipping well 6033005: max_r2_selected=0.301505836966045\n",
      "Skipping well 6033007: max_r2_selected=0.3071297426329085\n",
      "Skipping well 6034005: max_r2_selected=0.297637776069398\n",
      "Skipping well 6034010: max_r2_selected=0.0613079256810903\n",
      "Skipping well 6034017: max_r2_selected=0.3941900563972175\n",
      "Skipping well 6034019: max_r2_selected=0.0424784370547327\n",
      "Skipping well 6034020: max_r2_selected=0.2764210981931742\n",
      "Skipping well 6034021: max_r2_selected=0.0412114507499665\n",
      "Skipping well 6035005: max_r2_selected=0.2457739810812654\n",
      "Skipping well 6036002: max_r2_selected=0.185563135382605\n",
      "Skipping well 6037003: max_r2_selected=0.1600100087494421\n",
      "Skipping well 6037004: max_r2_selected=0.2041736682742165\n",
      "Skipping well 6037005: max_r2_selected=0.132293018908454\n",
      "Skipping well 6037009: max_r2_selected=0.3456491519965757\n",
      "Skipping well 6037010: max_r2_selected=0.3894400128494038\n",
      "Skipping well 6041004: max_r2_selected=0.3250513253802785\n",
      "Skipping well 6043003: max_r2_selected=0.1943313133050978\n",
      "Skipping well 6051005: max_r2_selected=0.3181364467571421\n",
      "Skipping well 6051006: max_r2_selected=0.1594332459165461\n",
      "Skipping well 6051008: max_r2_selected=0.2391323756196431\n",
      "Skipping well 6056004: max_r2_selected=0.0458516314534234\n",
      "Skipping well 6115001: max_r2_selected=0.3207888007197964\n",
      "Skipping well 6130005: max_r2_selected=0.3657230753098159\n",
      "\n",
      "LR models Finished! \n",
      "+Finito! \n",
      "+Terminado!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "######## Memory computation for GW ########\n",
    "\n",
    "# === Load R2 results ===\n",
    "df_gw = pd.read_csv('../2_run_LR_gw/csv/r2_LR_rest_pos_False_trained_all.csv', dtype={\"well_id\": str})\n",
    "df_q = pd.read_csv('../3_run_LR_Q/csv/r2_LR_rest_pos_False_trained_all.csv', dtype={\"well_id\": str})\n",
    "\n",
    "# Work on groundwater results in this notebook\n",
    "df = df_gw.copy()\n",
    "mask = (df['target'] == 'gw_an') & (df['predictor'] == 'pr_an')\n",
    "df = df[mask]\n",
    "\n",
    "# === Load predictions (used for time series plotting) ===\n",
    "predictions_file = '../2_run_LR_gw/csv/gw_sim_LR_trained_all.csv'\n",
    "# load only necessary columns if file large; adjust as needed\n",
    "df_pred = pd.read_csv(predictions_file, parse_dates=['date'], dtype={\"well_id\": str})\n",
    "mask = (df_pred['target'] == 'gw_an') & (df_pred['predictor'] == 'pr_an')\n",
    "df_pred = df_pred[mask]\n",
    "\n",
    "# selected_lag_type_q = 'type1_incr1'\n",
    "selected_lag_type_gw = 'type2_incr4'\n",
    "\n",
    "# === Create pred_memory1..6 columns from lag_ranges (explicit, no helper) ===\n",
    "pattern = r\"\\(?\\s*[-\\d.]+\\s*,\\s*([-\\d.]+)\\s*\\)?\"\n",
    "# initialize columns\n",
    "for i in range(1, 7):\n",
    "    df[f'pred_memory{i}'] = np.nan\n",
    "\n",
    "# iterate rows and extract\n",
    "for idx in df.index:\n",
    "    lr = df.at[idx, 'lag_ranges'] if 'lag_ranges' in df.columns else None\n",
    "    if lr is None:\n",
    "        vals = [np.nan] * 6\n",
    "    else:\n",
    "        s = str(lr)\n",
    "        matches = re.findall(pattern, s)\n",
    "        vals = []\n",
    "        for i in range(6):\n",
    "            if i < len(matches):\n",
    "                try:\n",
    "                    vals.append(float(matches[i]))\n",
    "                except Exception:\n",
    "                    vals.append(np.nan)\n",
    "            else:\n",
    "                vals.append(np.nan)\n",
    "    # assign\n",
    "    for j, v in enumerate(vals, start=1):\n",
    "        df.at[idx, f'pred_memory{j}'] = v\n",
    "\n",
    "# also keep an array column for backward compatibility\n",
    "if 'pred_memory' not in df.columns:\n",
    "    df['pred_memory'] = df.apply(lambda r: np.array([r[f'pred_memory{i}'] for i in range(1, 7)]), axis=1)\n",
    "\n",
    "\n",
    "# === Output ===\n",
    "out_figs = 'figs_gw'\n",
    "os.makedirs(out_figs, exist_ok=True)\n",
    "\n",
    "out_results = 'csv'\n",
    "os.makedirs(out_results, exist_ok=True)\n",
    "\n",
    "\n",
    "# === Model configurations and colors ===\n",
    "color_palette = plt.get_cmap('tab10')\n",
    "\n",
    "# only selected models with 6 predictors to avoid overfitting and misinterpreting results\n",
    "memory_summary = []\n",
    "\n",
    "# Create a deterministic color mapping from the available lag types\n",
    "lag_types_all = sorted(df['lag_type'].unique()) if 'lag_type' in df.columns else []\n",
    "# Specify colors by hand for the first three lag types; fallback to colormap for others\n",
    "specified_colors = ['blue', 'purple', 'green']\n",
    "model_colors = {}\n",
    "for i, name in enumerate(lag_types_all):\n",
    "    if i < len(specified_colors):\n",
    "        model_colors[name] = specified_colors[i]\n",
    "    else:\n",
    "        model_colors[name] = color_palette(i % 10)\n",
    "\n",
    "# === Plot per well ===\n",
    "# for well in ['3450005']:\n",
    "for well in sorted(df['well_id'].unique()):\n",
    "    well_data = df[df['well_id'] == well]\n",
    "    df_fit = well_data[well_data['lag_type'] == selected_lag_type_gw]\n",
    "    max_r2_selected = df_fit['r2_all'].max() if 'r2_all' in df_fit.columns else np.nan\n",
    "\n",
    "    # Only proceed with plotting if the selected model configs show sufficient performance\n",
    "    if np.isnan(max_r2_selected) or max_r2_selected <= 0.4:\n",
    "        print(f\"Skipping well {well}: max_r2_selected={max_r2_selected}\")\n",
    "        continue\n",
    "\n",
    "    fig = plt.figure(figsize=(13, 4))\n",
    "    gs = gridspec.GridSpec(1, 2, width_ratios=[3, 2])  # left panel wider\n",
    "    ax1 = fig.add_subplot(gs[0])\n",
    "    ax2 = fig.add_subplot(gs[1])\n",
    "\n",
    "    # Left plot: Observed vs predicted time series\n",
    "    pred_data = df_pred[df_pred['well_id'] == well].copy()\n",
    "\n",
    "    for name in sorted(well_data['lag_type'].unique()):\n",
    "        mask = (pred_data['lag_type'] == name) \n",
    "        pred_subset = pred_data[mask]\n",
    "        color = model_colors.get(name)\n",
    "        ax1.plot(\n",
    "            pred_subset['date'], pred_subset['pred'],\n",
    "            label=f'{name}',\n",
    "            color=color,\n",
    "            linestyle='-',\n",
    "            linewidth=1,\n",
    "            zorder=1,\n",
    "        )\n",
    "\n",
    "    # Plot observed values\n",
    "    obs = pred_data[pred_data['target'] == 'gw_an']\n",
    "    if not obs.empty and 'target_val' in obs.columns:\n",
    "        ax1.scatter(obs['date'], obs['target_val'], color='black', s=6, zorder=2)\n",
    "    ax1.set_title(f\"Well {well} – observed vs simulated GWL, R² = {np.round(max_r2_selected,2)}\", loc='left')\n",
    "    ax1.set_xlabel(\"Date\")\n",
    "    ax1.set_ylabel(\"GW anom (m)\")\n",
    "    ax1.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "    # Add legend only if prediction lines exist\n",
    "    handles, labels = ax1.get_legend_handles_labels()\n",
    "    if labels:\n",
    "        ax1.legend(fontsize=8)\n",
    "\n",
    "    # Right plot: R² vs memory\n",
    "    for name in sorted(well_data['lag_type'].unique()):\n",
    "        mask = (well_data['lag_type'] == name) & (well_data['target'] == 'gw_an') & (well_data['predictor'] == 'pr_an')\n",
    "        pred_subset = well_data[mask]\n",
    "        color = model_colors.get(name, 'red')\n",
    "        label = name\n",
    "        # make sure columns exist in pred_subset\n",
    "        xm = np.array([pred_subset['pred_memory1'],\n",
    "                      pred_subset['pred_memory2'],\n",
    "                      pred_subset['pred_memory3'],\n",
    "                      pred_subset['pred_memory4'],\n",
    "                      pred_subset['pred_memory5'],\n",
    "                      pred_subset['pred_memory6']])\n",
    "        ym = np.array([pred_subset['r2_pred1'],\n",
    "                      pred_subset['r2_pred2'],\n",
    "                      pred_subset['r2_pred3'],\n",
    "                      pred_subset['r2_pred4'],\n",
    "                      pred_subset['r2_pred5'],\n",
    "                      pred_subset['r2_pred6']])\n",
    "        \n",
    "        ax2.plot(xm, ym,label=label, marker='o', linestyle='None', color=color,zorder=2)\n",
    "   \n",
    "    # plot fitted curves\n",
    "    fit_results = compute_memory_from_spline_variants(df_fit)\n",
    "    if fit_results['x_vals'] is not None and fit_results['y_iso'] is not None:\n",
    "        ax2.plot(fit_results['x_vals'], fit_results['y_iso'], '--', color='grey', alpha=0.7, label=None, linewidth=.6)\n",
    "        # ax2.axvline(fit_results['memory_iso'], color='orange', linestyle='-', linewidth=.6)\n",
    "\n",
    "    if fit_results['x_vals'] is not None and fit_results['y_spline'] is not None:\n",
    "        ax2.plot(fit_results['x_vals'], fit_results['y_spline'], '--', color='grey', alpha=0.7, label=None, linewidth=.6)\n",
    "        # ax2.axvline(fit_results['memory_spline'], color='grey', linestyle='-', linewidth=.6)\n",
    "\n",
    "    if fit_results['x_vals'] is not None and fit_results['y_pchip'] is not None:\n",
    "        ax2.plot(fit_results['x_vals'], fit_results['y_pchip'], '--', color='grey', alpha=0.7, label=None, linewidth=.6)\n",
    "        # ax2.axvline(fit_results['memory_pchip'], color='blue', linestyle='-', linewidth=.6)\n",
    "\n",
    "    avg_memory = np.nanmean([fit_results.get('memory_iso', np.nan),\n",
    "                                fit_results.get('memory_spline', np.nan),\n",
    "                                fit_results.get('memory_pchip', np.nan)])\n",
    "    \n",
    "    ax2.axvline(avg_memory, color='black', linestyle='-', linewidth=.9, label='GW memory')\n",
    "    \n",
    "    ax2.set_title(f\"R² with increasing # of predictors\\nGW memory = {avg_memory:.0f} months\", loc='left')\n",
    "    ax2.set_xlabel(\"Pr_an lags (months)\")\n",
    "    ax2.set_ylabel(\"R²\")\n",
    "    ax2.grid(True, linestyle='--', alpha=0.5)\n",
    "    ax2.legend(fontsize=8)\n",
    "    ax2.set_xlim(df['pred_memory'].apply(lambda a: np.nanmin(a) if hasattr(a, '__iter__') else np.nan).min() - 5,\n",
    "                df['pred_memory'].apply(lambda a: np.nanmax(a) if hasattr(a, '__iter__') else np.nan).max() + 5)\n",
    "    # ax2.set_ylim(0, 1)\n",
    "\n",
    "    # save figure per well\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(out_figs, f\"gw_memory_{well}.png\"), bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "\n",
    "       # === Store memory results if at least one is valid ===\n",
    "    if not np.isnan(avg_memory):\n",
    "        memory_summary.append({\n",
    "            'well_id': well,\n",
    "            'gw_memory': avg_memory,\n",
    "            'max_r2_selected_configs': max_r2_selected\n",
    "        })\n",
    "\n",
    "\n",
    "# write summary\n",
    "if memory_summary:\n",
    "    df_memory_summary = pd.DataFrame(memory_summary)\n",
    "    out_csv = os.path.join(out_results, 'gw_memory.csv')\n",
    "    # ensure overwrite by removing existing file first\n",
    "    try:\n",
    "        if os.path.exists(out_csv):\n",
    "            os.remove(out_csv)\n",
    "    except Exception:\n",
    "        pass\n",
    "    df_memory_summary.to_csv(out_csv, index=False)\n",
    "else:\n",
    "    print('No memory results to save')\n",
    "\n",
    "print(\"\\nLR models Finished! \\n+Finito! \\n+Terminado!\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de8f247f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping basin 1001001: max_r2_selected=0.1143564312261744\n",
      "Skipping basin 1001002: max_r2_selected=0.2904842766013357\n",
      "Skipping basin 1001003: max_r2_selected=0.2519439274177124\n",
      "Skipping basin 10100006: max_r2_selected=0.3460514843782227\n",
      "Skipping basin 1020002: max_r2_selected=0.1569168968894412\n",
      "Skipping basin 1020003: max_r2_selected=0.1320083037914224\n",
      "Skipping basin 1021001: max_r2_selected=0.2563804084765678\n",
      "Skipping basin 1021002: max_r2_selected=0.0213146085466234\n",
      "Skipping basin 10311001: max_r2_selected=0.376188436813146\n",
      "Skipping basin 10322003: max_r2_selected=0.2477885113030353\n",
      "Skipping basin 10401001: max_r2_selected=0.2557415064019299\n",
      "Skipping basin 1041002: max_r2_selected=0.1109800508006249\n",
      "Skipping basin 10431001: max_r2_selected=0.1040507877804109\n",
      "Skipping basin 1044001: max_r2_selected=0.2834457028134745\n",
      "Skipping basin 1050002: max_r2_selected=0.0401917763187656\n",
      "Skipping basin 1050004: max_r2_selected=0.0857539795273372\n",
      "Skipping basin 10503001: max_r2_selected=0.3261655441852091\n",
      "Skipping basin 11130001: max_r2_selected=0.1217950616139805\n",
      "Skipping basin 11141001: max_r2_selected=0.2437733846768215\n",
      "Skipping basin 11143001: max_r2_selected=0.3893158164841118\n",
      "Skipping basin 11143002: max_r2_selected=0.1661311927817456\n",
      "Skipping basin 11147002: max_r2_selected=0.2552728598086001\n",
      "Skipping basin 11307001: max_r2_selected=0.3819401706342085\n",
      "Skipping basin 11310001: max_r2_selected=0.3772226973387781\n",
      "Skipping basin 11310002: max_r2_selected=0.0874290492633195\n",
      "Skipping basin 11310003: max_r2_selected=0.3729142461408199\n",
      "Skipping basin 11312001: max_r2_selected=0.2424122438384432\n",
      "Skipping basin 11315001: max_r2_selected=0.3729927332344562\n",
      "Skipping basin 11316001: max_r2_selected=0.3957734418084676\n",
      "Skipping basin 11335002: max_r2_selected=0.3824786891018291\n",
      "Skipping basin 11505001: max_r2_selected=0.3117862418057029\n",
      "Skipping basin 11520002: max_r2_selected=0.0897026668144284\n",
      "Skipping basin 11521001: max_r2_selected=0.0648640743847808\n",
      "Skipping basin 11536001: max_r2_selected=0.3500013940325366\n",
      "Skipping basin 11545000: max_r2_selected=0.3265927187265798\n",
      "Skipping basin 11701001: max_r2_selected=0.2464730483117377\n",
      "Skipping basin 11710000: max_r2_selected=0.186004747793222\n",
      "Skipping basin 11711000: max_r2_selected=0.2534079020964109\n",
      "Skipping basin 1201001: max_r2_selected=0.1584925108067649\n",
      "Skipping basin 1201003: max_r2_selected=0.1827972696959741\n",
      "Skipping basin 1201005: max_r2_selected=0.2161037865807438\n",
      "Skipping basin 1210001: max_r2_selected=0.0670244921832349\n",
      "Skipping basin 1211001: max_r2_selected=0.1542263511521084\n",
      "Skipping basin 12280002: max_r2_selected=0.1147459941239877\n",
      "Skipping basin 12284002: max_r2_selected=0.1507040986662232\n",
      "Skipping basin 12284003: max_r2_selected=0.1745436219644652\n",
      "Skipping basin 12284005: max_r2_selected=0.0641809352731832\n",
      "Skipping basin 12284006: max_r2_selected=0.2745035642393716\n",
      "Skipping basin 12284007: max_r2_selected=0.2755126049367853\n",
      "Skipping basin 12285001: max_r2_selected=0.0800241538660138\n",
      "Skipping basin 12285003: max_r2_selected=0.3674422325193755\n",
      "Skipping basin 12287001: max_r2_selected=0.0469881251619559\n",
      "Skipping basin 12288003: max_r2_selected=0.3315015737250362\n",
      "Skipping basin 12289001: max_r2_selected=0.1241323744557459\n",
      "Skipping basin 12289002: max_r2_selected=0.3445039838766879\n",
      "Skipping basin 12289003: max_r2_selected=0.1055969975676968\n",
      "Skipping basin 12400003: max_r2_selected=0.1503117237382861\n",
      "Skipping basin 12400004: max_r2_selected=0.2839123226631279\n",
      "Skipping basin 12448001: max_r2_selected=0.3855833205114439\n",
      "Skipping basin 12452001: max_r2_selected=0.3847684919955194\n",
      "Skipping basin 12561001: max_r2_selected=0.2176801076113204\n",
      "Skipping basin 12582001: max_r2_selected=0.2593042157010505\n",
      "Skipping basin 12585001: max_r2_selected=0.0776942408697631\n",
      "Skipping basin 12586001: max_r2_selected=0.0663188088474878\n",
      "Skipping basin 12600001: max_r2_selected=0.234085979913047\n",
      "Skipping basin 12622001: max_r2_selected=0.1250799176288225\n",
      "Skipping basin 12660001: max_r2_selected=0.0630310753621973\n",
      "Skipping basin 12802001: max_r2_selected=0.111122379640411\n",
      "Skipping basin 12805001: max_r2_selected=0.0924172609736235\n",
      "Skipping basin 12806001: max_r2_selected=0.1363404561118789\n",
      "Skipping basin 12820001: max_r2_selected=0.1673045486392259\n",
      "Skipping basin 12861001: max_r2_selected=0.3543529202351443\n",
      "Skipping basin 12863002: max_r2_selected=0.1484329972880373\n",
      "Skipping basin 12865001: max_r2_selected=0.1521048028238494\n",
      "Skipping basin 12872001: max_r2_selected=0.2144944573656924\n",
      "Skipping basin 12876001: max_r2_selected=0.3656345859764949\n",
      "Skipping basin 12876004: max_r2_selected=0.2685534622908713\n",
      "Skipping basin 12878001: max_r2_selected=0.2300812571289714\n",
      "Skipping basin 12930001: max_r2_selected=0.1678592277307007\n",
      "Skipping basin 1300009: max_r2_selected=0.2603237754086477\n",
      "Skipping basin 1310002: max_r2_selected=0.141371380523646\n",
      "Skipping basin 1410004: max_r2_selected=0.0516580138270653\n",
      "Skipping basin 1502002: max_r2_selected=0.1228685021089266\n",
      "Skipping basin 1502008: max_r2_selected=0.0549460408559472\n",
      "Skipping basin 1610004: max_r2_selected=0.3099822591829865\n",
      "Skipping basin 1730001: max_r2_selected=0.2982581642404253\n",
      "Skipping basin 1730002: max_r2_selected=0.1536789009759341\n",
      "Skipping basin 1730003: max_r2_selected=0.14158097841509\n",
      "Skipping basin 1730007: max_r2_selected=0.2047054983442849\n",
      "Skipping basin 1730012: max_r2_selected=0.0919150398766813\n",
      "Skipping basin 2101001: max_r2_selected=0.0252651210474709\n",
      "Skipping basin 2103001: max_r2_selected=0.0023843724248802\n",
      "Skipping basin 2103002: max_r2_selected=0.0141233910686076\n",
      "Skipping basin 2103003: max_r2_selected=0.0695966904812838\n",
      "Skipping basin 2103014: max_r2_selected=0.1374908881295657\n",
      "Skipping basin 2104002: max_r2_selected=0.1594392095381222\n",
      "Skipping basin 2104003: max_r2_selected=0.2735800384271954\n",
      "Skipping basin 2104013: max_r2_selected=0.3314200217786217\n",
      "Skipping basin 2105001: max_r2_selected=0.0573891965765067\n",
      "Skipping basin 2105002: max_r2_selected=0.2891904382865191\n",
      "Skipping basin 2105005: max_r2_selected=0.2579691594018213\n",
      "Skipping basin 2105007: max_r2_selected=0.0177108369017966\n",
      "Skipping basin 2110001: max_r2_selected=0.0419862564754209\n",
      "Skipping basin 2110002: max_r2_selected=0.0346782226213055\n",
      "Skipping basin 2110004: max_r2_selected=0.1590617017211704\n",
      "Skipping basin 2112005: max_r2_selected=0.0129939639183482\n",
      "Skipping basin 2112006: max_r2_selected=0.21983083131638\n",
      "Skipping basin 2112007: max_r2_selected=0.1839466641319135\n",
      "Skipping basin 2113001: max_r2_selected=0.0707230081637422\n",
      "Skipping basin 2120001: max_r2_selected=0.197764941538852\n",
      "Skipping basin 2510001: max_r2_selected=0.1137316839883826\n",
      "Skipping basin 3022001: max_r2_selected=0.1360632914833215\n",
      "Skipping basin 3041001: max_r2_selected=0.2351827174397242\n",
      "Skipping basin 3041002: max_r2_selected=0.0719835385580177\n",
      "Skipping basin 3041003: max_r2_selected=0.1960368194428468\n",
      "Skipping basin 3041004: max_r2_selected=0.0239015533138297\n",
      "Skipping basin 3041005: max_r2_selected=0.0291960694909987\n",
      "Skipping basin 3050001: max_r2_selected=0.1195735975697972\n",
      "Skipping basin 3404001: max_r2_selected=0.3773695262687758\n",
      "Skipping basin 3421001: max_r2_selected=0.3669252389513546\n",
      "Skipping basin 3430001: max_r2_selected=0.2276346995943407\n",
      "Skipping basin 3434001: max_r2_selected=0.3811663057052477\n",
      "Skipping basin 3453001: max_r2_selected=0.2780905220744595\n",
      "Skipping basin 3825001: max_r2_selected=0.3413144838111699\n",
      "Skipping basin 4335001: max_r2_selected=0.3776241529848875\n",
      "Skipping basin 4400001: max_r2_selected=0.1653314351589579\n",
      "Skipping basin 4503001: max_r2_selected=0.2690974743494937\n",
      "Skipping basin 4520001: max_r2_selected=0.3677056486036655\n",
      "Skipping basin 4531001: max_r2_selected=0.3984678664099832\n",
      "Skipping basin 4533002: max_r2_selected=0.123868687734041\n",
      "Skipping basin 4535002: max_r2_selected=0.3417817495575209\n",
      "Skipping basin 4540001: max_r2_selected=0.2231804238652297\n",
      "Skipping basin 4550003: max_r2_selected=0.080777593791556\n",
      "Skipping basin 4556001: max_r2_selected=0.3906226089928126\n",
      "Skipping basin 4557002: max_r2_selected=0.2478665324974848\n",
      "Skipping basin 4723001: max_r2_selected=0.3978707609664795\n",
      "Skipping basin 4810005: max_r2_selected=0.3237374307087348\n",
      "Skipping basin 5120001: max_r2_selected=0.3041840966531934\n",
      "Skipping basin 5221002: max_r2_selected=0.3066585042943512\n",
      "Skipping basin 5402001: max_r2_selected=0.320975515897931\n",
      "Skipping basin 5403002: max_r2_selected=0.3804533837241882\n",
      "Skipping basin 5420002: max_r2_selected=0.2081742397487078\n",
      "Skipping basin 5421001: max_r2_selected=0.2805086632317186\n",
      "Skipping basin 5421002: max_r2_selected=0.1530218532167722\n",
      "Skipping basin 5422001: max_r2_selected=0.138518283699407\n",
      "Skipping basin 5423004: max_r2_selected=0.2036308705834334\n",
      "Skipping basin 5703006: max_r2_selected=0.1636578359515429\n",
      "Skipping basin 5705001: max_r2_selected=0.3632141214164637\n",
      "Skipping basin 5706001: max_r2_selected=0.1935921635195494\n",
      "Skipping basin 5721016: max_r2_selected=0.302103916470836\n",
      "Skipping basin 5730005: max_r2_selected=0.2310656953889727\n",
      "Skipping basin 5730008: max_r2_selected=0.2980932195054649\n",
      "Skipping basin 5734001: max_r2_selected=0.3760052798719789\n",
      "Skipping basin 5741001: max_r2_selected=0.3194521569838411\n",
      "Skipping basin 6003001: max_r2_selected=0.3026744359063517\n",
      "Skipping basin 6011001: max_r2_selected=0.3361510333355273\n",
      "Skipping basin 6033011: max_r2_selected=0.3273990140889387\n",
      "Skipping basin 6034022: max_r2_selected=0.2097877608087166\n",
      "Skipping basin 6034023: max_r2_selected=0.3136489870210487\n",
      "Skipping basin 7300001: max_r2_selected=0.1501325385312736\n",
      "Skipping basin 7303000: max_r2_selected=0.3090438292272609\n",
      "Skipping basin 7306001: max_r2_selected=0.3385207127790025\n",
      "Skipping basin 7308002: max_r2_selected=0.1943282258590361\n",
      "Skipping basin 7317003: max_r2_selected=0.3237890580629464\n",
      "Skipping basin 7321002: max_r2_selected=0.2639707308180294\n",
      "Skipping basin 7331001: max_r2_selected=0.1712202510903738\n",
      "Skipping basin 7340001: max_r2_selected=0.2729160242232001\n",
      "Skipping basin 7355003: max_r2_selected=0.3853138830030553\n",
      "Skipping basin 7358001: max_r2_selected=0.1357720514331326\n",
      "Skipping basin 8210003: max_r2_selected=0.2460906584871267\n",
      "Skipping basin 8220001: max_r2_selected=0.294978879511011\n",
      "Skipping basin 8312000: max_r2_selected=0.1037089278949473\n",
      "Skipping basin 8313000: max_r2_selected=0.1149757392416338\n",
      "Skipping basin 8319001: max_r2_selected=0.3302743071915079\n",
      "Skipping basin 8324002: max_r2_selected=0.1604409764266064\n",
      "Skipping basin 8366002: max_r2_selected=0.0511889009281653\n",
      "Skipping basin 8372002: max_r2_selected=0.2210654506892432\n",
      "Skipping basin 8380001: max_r2_selected=0.3443383671351958\n",
      "Skipping basin 8381003: max_r2_selected=0.2019824889955631\n",
      "Skipping basin 8386001: max_r2_selected=0.1416372156563958\n",
      "Skipping basin 8393002: max_r2_selected=0.1269822466787926\n",
      "Skipping basin 8700002: max_r2_selected=0.270482142186537\n",
      "Skipping basin 8720001: max_r2_selected=0.2579538399403241\n",
      "Skipping basin 8821001: max_r2_selected=0.30316444388393\n",
      "Skipping basin 8821002: max_r2_selected=0.2045171667851793\n",
      "Skipping basin 8821006: max_r2_selected=0.3976454756609286\n",
      "Skipping basin 8822001: max_r2_selected=0.2417297973602133\n",
      "Skipping basin 9101002: max_r2_selected=0.3144588279551375\n",
      "Skipping basin 9111001: max_r2_selected=0.2964179921639385\n",
      "\n",
      "LR models Finished! \n",
      "+Finito! \n",
      "+Terminado!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "######## Memory computation for STREAMFLOW ########\n",
    "\n",
    "# === Load R2 results ===\n",
    "# df_gw = pd.read_csv('../2_run_LR_gw/csv/r2_LR_rest_pos_False_trained_all.csv', dtype={\"well_id\": str})\n",
    "df_q = pd.read_csv('../3_run_LR_Q/csv/r2_LR_rest_pos_False_trained_all.csv', dtype={\"gauge_id\": str})\n",
    "\n",
    "# Work on groundwater results in this notebook\n",
    "df = df_q.copy()\n",
    "mask = (df['target'] == 'q_an') & (df['predictor'] == 'pr_an')\n",
    "df = df[mask]\n",
    "\n",
    "# === Load predictions (used for time series plotting) ===\n",
    "predictions_file = '../3_run_LR_Q/csv/q_sim_LR_trained_all.csv'\n",
    "# load only necessary columns if file large; adjust as needed\n",
    "df_pred = pd.read_csv(predictions_file, parse_dates=['date'], dtype={\"gauge_id\": str})\n",
    "mask = (df_pred['target'] == 'q_an') & (df_pred['predictor'] == 'pr_an')\n",
    "df_pred = df_pred[mask]\n",
    "\n",
    "selected_lag_type_q = 'type1_incr1'\n",
    "# selected_lag_type_gw = 'type2_incr4'\n",
    "\n",
    "# === Create pred_memory1..6 columns from lag_ranges (explicit, no helper) ===\n",
    "pattern = r\"\\(?\\s*[-\\d.]+\\s*,\\s*([-\\d.]+)\\s*\\)?\"\n",
    "# initialize columns\n",
    "for i in range(1, 7):\n",
    "    df[f'pred_memory{i}'] = np.nan\n",
    "\n",
    "# iterate rows and extract\n",
    "for idx in df.index:\n",
    "    lr = df.at[idx, 'lag_ranges'] if 'lag_ranges' in df.columns else None\n",
    "    if lr is None:\n",
    "        vals = [np.nan] * 6\n",
    "    else:\n",
    "        s = str(lr)\n",
    "        matches = re.findall(pattern, s)\n",
    "        vals = []\n",
    "        for i in range(6):\n",
    "            if i < len(matches):\n",
    "                try:\n",
    "                    vals.append(float(matches[i]))\n",
    "                except Exception:\n",
    "                    vals.append(np.nan)\n",
    "            else:\n",
    "                vals.append(np.nan)\n",
    "    # assign\n",
    "    for j, v in enumerate(vals, start=1):\n",
    "        df.at[idx, f'pred_memory{j}'] = v\n",
    "\n",
    "# also keep an array column for backward compatibility\n",
    "if 'pred_memory' not in df.columns:\n",
    "    df['pred_memory'] = df.apply(lambda r: np.array([r[f'pred_memory{i}'] for i in range(1, 7)]), axis=1)\n",
    "\n",
    "\n",
    "# === Output ===\n",
    "out_figs = 'figs_q'\n",
    "os.makedirs(out_figs, exist_ok=True)\n",
    "\n",
    "out_results = 'csv'\n",
    "os.makedirs(out_results, exist_ok=True)\n",
    "\n",
    "\n",
    "# === Model configurations and colors ===\n",
    "color_palette = plt.get_cmap('tab10')\n",
    "\n",
    "# only selected models with 6 predictors to avoid overfitting and misinterpreting results\n",
    "memory_summary = []\n",
    "\n",
    "# Create a deterministic color mapping from the available lag types\n",
    "lag_types_all = sorted(df['lag_type'].unique()) if 'lag_type' in df.columns else []\n",
    "# Specify colors by hand for the first three lag types; fallback to colormap for others\n",
    "specified_colors = ['blue', 'purple', 'green']\n",
    "model_colors = {}\n",
    "for i, name in enumerate(lag_types_all):\n",
    "    if i < len(specified_colors):\n",
    "        model_colors[name] = specified_colors[i]\n",
    "    else:\n",
    "        model_colors[name] = color_palette(i % 10)\n",
    "\n",
    "# === Plot per well ===\n",
    "# for well in ['5715001']:\n",
    "for well in sorted(df['gauge_id'].unique()):\n",
    "    well_data = df[df['gauge_id'] == well]\n",
    "    df_fit = well_data[well_data['lag_type'] == selected_lag_type_q]\n",
    "    max_r2_selected = df_fit['r2_all'].max() if 'r2_all' in df_fit.columns else np.nan\n",
    "\n",
    "    # Only proceed with plotting if the selected model configs show sufficient performance\n",
    "    if np.isnan(max_r2_selected) or max_r2_selected <= 0.4:\n",
    "        print(f\"Skipping basin {well}: max_r2_selected={max_r2_selected}\")\n",
    "        continue\n",
    "\n",
    "    fig = plt.figure(figsize=(13, 4))\n",
    "    gs = gridspec.GridSpec(1, 2, width_ratios=[3, 2])  # left panel wider\n",
    "    ax1 = fig.add_subplot(gs[0])\n",
    "    ax2 = fig.add_subplot(gs[1])\n",
    "\n",
    "    # Left plot: Observed vs predicted time series\n",
    "    pred_data = df_pred[df_pred['gauge_id'] == well].copy()\n",
    "\n",
    "    for name in sorted(well_data['lag_type'].unique()):\n",
    "        mask = (pred_data['lag_type'] == name) \n",
    "        pred_subset = pred_data[mask]\n",
    "        color = model_colors.get(name)\n",
    "        ax1.plot(\n",
    "            pred_subset['date'], pred_subset['pred'],\n",
    "            label=f'{name}',\n",
    "            color=color,\n",
    "            linestyle='-',\n",
    "            linewidth=1,\n",
    "            zorder=1,\n",
    "        )\n",
    "\n",
    "    # Plot observed values\n",
    "    obs = pred_data[pred_data['target'] == 'q_an']\n",
    "    if not obs.empty and 'target_val' in obs.columns:\n",
    "        ax1.scatter(obs['date'], obs['target_val'], color='black', s=6, zorder=2)\n",
    "    ax1.set_title(f\"Basin {well} – observed vs simulated Q, R² = {np.round(max_r2_selected,2)}\", loc='left')\n",
    "    ax1.set_xlabel(\"Date\")\n",
    "    ax1.set_ylabel(\"Q anom (m3/s)\")\n",
    "    ax1.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "    # Add legend only if prediction lines exist\n",
    "    handles, labels = ax1.get_legend_handles_labels()\n",
    "    if labels:\n",
    "        ax1.legend(fontsize=8)\n",
    "\n",
    "    # Right plot: R² vs memory\n",
    "    for name in sorted(well_data['lag_type'].unique()):\n",
    "        mask = (well_data['lag_type'] == name) & (well_data['target'] == 'q_an') & (well_data['predictor'] == 'pr_an')\n",
    "        pred_subset = well_data[mask]\n",
    "        color = model_colors.get(name, 'red')\n",
    "        label = name\n",
    "        # make sure columns exist in pred_subset\n",
    "        xm = np.array([pred_subset['pred_memory1'],\n",
    "                      pred_subset['pred_memory2'],\n",
    "                      pred_subset['pred_memory3'],\n",
    "                      pred_subset['pred_memory4'],\n",
    "                      pred_subset['pred_memory5'],\n",
    "                      pred_subset['pred_memory6']])\n",
    "        ym = np.array([pred_subset['r2_pred1'],\n",
    "                      pred_subset['r2_pred2'],\n",
    "                      pred_subset['r2_pred3'],\n",
    "                      pred_subset['r2_pred4'],\n",
    "                      pred_subset['r2_pred5'],\n",
    "                      pred_subset['r2_pred6']])\n",
    "        \n",
    "        ax2.plot(xm, ym,label=label, marker='o', linestyle='None', color=color,zorder=2)\n",
    "   \n",
    "    # plot fitted curves\n",
    "    fit_results = compute_memory_from_spline_variants(df_fit)\n",
    "    if fit_results['x_vals'] is not None and fit_results['y_iso'] is not None:\n",
    "        ax2.plot(fit_results['x_vals'], fit_results['y_iso'], '--', color='grey', alpha=0.7, label=None, linewidth=.6)\n",
    "        # ax2.axvline(fit_results['memory_iso'], color='orange', linestyle='-', linewidth=.6)\n",
    "\n",
    "    if fit_results['x_vals'] is not None and fit_results['y_spline'] is not None:\n",
    "        ax2.plot(fit_results['x_vals'], fit_results['y_spline'], '--', color='grey', alpha=0.7, label=None, linewidth=.6)\n",
    "        # ax2.axvline(fit_results['memory_spline'], color='grey', linestyle='-', linewidth=.6)\n",
    "\n",
    "    if fit_results['x_vals'] is not None and fit_results['y_pchip'] is not None:\n",
    "        ax2.plot(fit_results['x_vals'], fit_results['y_pchip'], '--', color='grey', alpha=0.7, label=None, linewidth=.6)\n",
    "        # ax2.axvline(fit_results['memory_pchip'], color='blue', linestyle='-', linewidth=.6)\n",
    "\n",
    "    avg_memory = np.nanmean([fit_results.get('memory_iso', np.nan),\n",
    "                                fit_results.get('memory_spline', np.nan),\n",
    "                                fit_results.get('memory_pchip', np.nan)])\n",
    "    \n",
    "    ax2.axvline(avg_memory, color='black', linestyle='-', linewidth=.9, label='GW memory')\n",
    "    \n",
    "    ax2.set_title(f\"R² with increasing # of predictors\\nQ memory = {avg_memory:.0f} months\", loc='left')\n",
    "    ax2.set_xlabel(\"Pr_an lags (months)\")\n",
    "    ax2.set_ylabel(\"R²\")\n",
    "    ax2.grid(True, linestyle='--', alpha=0.5)\n",
    "    ax2.legend(fontsize=8)\n",
    "    ax2.set_xlim(df['pred_memory'].apply(lambda a: np.nanmin(a) if hasattr(a, '__iter__') else np.nan).min() - 5,\n",
    "                df['pred_memory'].apply(lambda a: np.nanmax(a) if hasattr(a, '__iter__') else np.nan).max() + 5)\n",
    "    # ax2.set_ylim(0, 1)\n",
    "\n",
    "    # save figure per well\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(out_figs, f\"q_memory_{well}.png\"), bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "\n",
    "       # === Store memory results if at least one is valid ===\n",
    "    if not np.isnan(avg_memory):\n",
    "        memory_summary.append({\n",
    "            'gauge_id': well,\n",
    "            'q_memory': avg_memory,\n",
    "            'max_r2_selected_configs': max_r2_selected\n",
    "        })\n",
    "\n",
    "\n",
    "# write summary\n",
    "if memory_summary:\n",
    "    df_memory_summary = pd.DataFrame(memory_summary)\n",
    "    out_csv = os.path.join(out_results, 'q_memory.csv')\n",
    "    try:\n",
    "        if os.path.exists(out_csv):\n",
    "            os.remove(out_csv)\n",
    "    except Exception:\n",
    "        pass\n",
    "    df_memory_summary.to_csv(out_csv, index=False)\n",
    "else:\n",
    "    print('No memory results to save')\n",
    "\n",
    "print(\"\\nLR models Finished! \\n+Finito! \\n+Terminado!\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
