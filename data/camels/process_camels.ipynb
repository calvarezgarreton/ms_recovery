{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41e99a80-d577-4df1-85ba-b51b4ae04a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from IPython.display import display\n",
    "from scipy.stats import pearsonr\n",
    "import seaborn as sns\n",
    "from scipy.optimize import nnls  # for non-negative least squares\n",
    "from scipy.stats import linregress\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "rc('mathtext', default='regular')\n",
    "from fun_LR_hydro_memory import *  # uses get_gauge_id()\n",
    "\n",
    "# === Paths ===\n",
    "root = '/Users/cag/Dropbox/0_Research/A_Fondecyts/2024_CAG_Ini_11240924/fdcyt_cag_GW_analysis/Analysis_cag_mid'\n",
    "path_join_camels = root + '/data/gwl_dga_inner_join_with_CAMELScl_basins.csv'\n",
    "path_join_bna    = root + '/data/gwl_dga_inner_join_with_BNA_basins.csv'\n",
    "\n",
    "# === Load data ===\n",
    "# Streamflow (monthly), one column per station, 'date' column as pandas datetime\n",
    "q_all      = pd.read_csv(root + '/data/q_mm_dga_mon_ts_1960_2025.csv', parse_dates=['Index'])\n",
    "\n",
    "# Predictors (monthly)\n",
    "pr_camels  = pd.read_csv(root + '/data/cr2met_v2p5R1_pr_mon_CAMELScl_ts_1960_2025.csv', parse_dates=['Index'])\n",
    "pr_bna     = pd.read_csv(root + '/data/cr2met_v2p5R1_pr_mon_BNA_ts_1960_2025.csv',    parse_dates=['Index'])\n",
    "et_camels = pd.read_csv(root + '/data/et_wb_mm_mon_cr2met_v2.5_cr2luc_beta_camels_v2025_ts.csv', parse_dates=['date'])\n",
    "\n",
    "stations = [col for col in q_all.columns if col != 'Index']\n",
    "\n",
    "# === Global parameters ===\n",
    "start = \"1960-01-01\"\n",
    "end   = \"2025-12-31\"\n",
    "min_obs = 100   # min monthly obs per station to be kept\n",
    "\n",
    "# === Pre-allocate collectors ===\n",
    "basin_pr_all = pd.DataFrame()\n",
    "basin_et_all = pd.DataFrame()\n",
    "basin_q_all  = pd.DataFrame()\n",
    "\n",
    "# === Build aligned station-by-station tables ===\n",
    "for cod in stations:\n",
    "    q = pd.Series(q_all[cod].values, index=q_all['Index'])\n",
    "    q_ser = pd.Series(q.values, index=q.index, name=cod)\n",
    "\n",
    "    if q.notna().sum() < min_obs:\n",
    "        continue  # Skip station with too few months\n",
    "\n",
    "    # Map station -> predictor basin id (CAMELS/BNA)\n",
    "    # gauge_id, predictor_source = get_gauge_id(cod, path_join_camels, path_join_bna)\n",
    "    gauge_id = cod\n",
    "    predictor_source = 'camels'\n",
    "\n",
    "    if predictor_source == \"camels\":\n",
    "        pr_ser = pd.Series(pr_camels[gauge_id].values, index=pr_camels['Index'], name=cod)\n",
    "        et_ser = pd.Series(et_camels[gauge_id].values, index=et_camels['date'],   name=cod)\n",
    "\n",
    "    elif predictor_source == \"bna\":\n",
    "        pr_ser = pd.Series(pr_bna[gauge_id].values, index=pr_bna['Index'], name=cod)\n",
    "        et_ser = pd.Series(et_bna[gauge_id].values, index=et_bna['date'],  name=cod)\n",
    "\n",
    "    else:\n",
    "        print(f\"⚠️ Predictors not available for station {cod}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Align time span to common overlap\n",
    "    # start = max(q_ser.index.min(), pr_ser.index.min(), et_ser.index.min())\n",
    "    # end   = min(q_ser.index.max(), pr_ser.index.max(), et_ser.index.max())\n",
    "\n",
    "    q_ser  = q_ser.sort_index().loc[start:end]\n",
    "    pr_ser = pr_ser.sort_index().loc[start:end]\n",
    "    et_ser = et_ser.sort_index().loc[start:end]\n",
    "\n",
    "    # Append to dataframes (outer join over time index)\n",
    "    basin_q_all  = basin_q_all.join(q_ser,  how='outer') if not basin_q_all.empty  else q_ser.to_frame()\n",
    "    basin_pr_all = basin_pr_all.join(pr_ser, how='outer') if not basin_pr_all.empty else pr_ser.to_frame()\n",
    "    basin_et_all = basin_et_all.join(et_ser, how='outer') if not basin_et_all.empty else et_ser.to_frame()\n",
    "\n",
    "# === Compute monthly anomalies (deseasonalize by calendar-month mean) ===\n",
    "if basin_q_all.empty:\n",
    "    print(\"⚠️ No stations passed filtering — nothing to save.\")\n",
    "else:\n",
    "    q_an  = basin_q_all  - basin_q_all.groupby(basin_q_all.index.month).transform('mean')\n",
    "    pr_an = basin_pr_all - basin_pr_all.groupby(basin_pr_all.index.month).transform('mean')\n",
    "    et_an = basin_et_all - basin_et_all.groupby(basin_et_all.index.month).transform('mean')\n",
    "\n",
    "    # === Save results ===\n",
    "    out_dir = os.path.join(root, \"data/camels_q_p_et_combined\")\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    # Raw (aligned) series\n",
    "    raw_to_save = [\n",
    "        (\"camels_q.csv\",  basin_q_all),\n",
    "        (\"camels_pr.csv\", basin_pr_all),\n",
    "        (\"camels_et.csv\", basin_et_all),\n",
    "    ]\n",
    "    for fname, df in raw_to_save:\n",
    "        df = df.sort_index()\n",
    "        df.index.name = \"date\"\n",
    "        df.to_csv(os.path.join(out_dir, fname))\n",
    "\n",
    "    # Monthly anomalies\n",
    "    an_to_save = [\n",
    "        (\"camels_q_an.csv\",  q_an),\n",
    "        (\"camels_pr_an.csv\", pr_an),\n",
    "        (\"camels_et_an.csv\", et_an),\n",
    "    ]\n",
    "    for fname, df in an_to_save:\n",
    "        df = df.sort_index()\n",
    "        df.index.name = \"date\"\n",
    "        df.to_csv(os.path.join(out_dir, fname))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da364ee9-880f-40e3-9f5a-9856878d0dce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12930001'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "445920c9-4bed-412c-b962-0673666056dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2020-12-01 00:00:00')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(q_ser.index.max(), pr_ser.index.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a6eda7c-af33-4f25-8442-1806c35cd0be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2020-12-01 00:00:00')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_ser.index.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9962ae58-9118-4587-8943-6a05369dca75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
